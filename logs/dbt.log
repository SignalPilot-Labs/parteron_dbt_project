[0m14:23:35.891280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aee2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad361e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad35a90>]}


============================== 14:23:35.895166 | 8b914c21-5fc9-440c-8c50-ac3ea93e9753 ==============================
[0m14:23:35.895166 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:23:35.895520 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'quiet': 'False', 'static_parser': 'True', 'no_print': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'log_format': 'default', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'partial_parse': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'use_colors': 'True', 'debug': 'False'}
[0m14:23:35.907038 [info ] [MainThread]: dbt version: 1.11.0-rc3
[0m14:23:35.907331 [info ] [MainThread]: python version: 3.12.12
[0m14:23:35.907523 [info ] [MainThread]: python path: /Users/tarik/miniconda3/envs/sp2/bin/python3.12
[0m14:23:35.907669 [info ] [MainThread]: os info: macOS-26.1-arm64-arm-64bit
[0m14:23:35.911677 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'DATABRICKS_HOST'
[0m14:23:35.913419 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.072633795, "process_in_blocks": "0", "process_kernel_time": 0.16608, "process_mem_max_rss": "132808704", "process_out_blocks": "0", "process_user_time": 1.354975}
[0m14:23:35.913708 [debug] [MainThread]: Command `dbt debug` failed at 14:23:35.913656 after 0.07 seconds
[0m14:23:35.913903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad35dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e3c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acce7b0>]}
[0m14:23:35.914091 [debug] [MainThread]: Flushing usage events
[0m14:23:36.388238 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:03.392556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1291545f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12942e7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12942e0c0>]}


============================== 14:24:03.396234 | 9f24fad4-c8ce-4ef0-8441-bebf09789d0c ==============================
[0m14:24:03.396234 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:24:03.396566 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'no_print': 'None', 'static_parser': 'True', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'quiet': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'version_check': 'True', 'log_format': 'default', 'empty': 'None', 'target_path': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'debug': 'False', 'warn_error': 'None', 'indirect_selection': 'eager'}
[0m14:24:03.407533 [info ] [MainThread]: dbt version: 1.11.0-rc3
[0m14:24:03.407871 [info ] [MainThread]: python version: 3.12.12
[0m14:24:03.408083 [info ] [MainThread]: python path: /Users/tarik/miniconda3/envs/sp2/bin/python3.12
[0m14:24:03.408220 [info ] [MainThread]: os info: macOS-26.1-arm64-arm-64bit
[0m14:24:03.411675 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'DATABRICKS_HOST'
[0m14:24:03.413638 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.06412275, "process_in_blocks": "0", "process_kernel_time": 0.184678, "process_mem_max_rss": "133726208", "process_out_blocks": "0", "process_user_time": 1.386537}
[0m14:24:03.414015 [debug] [MainThread]: Command `dbt debug` failed at 14:24:03.413960 after 0.06 seconds
[0m14:24:03.414227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1280ffd40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129013470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1293cf320>]}
[0m14:24:03.414448 [debug] [MainThread]: Flushing usage events
[0m14:24:03.708552 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:26:00.251911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062c55b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741f920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741f1d0>]}


============================== 14:26:00.255753 | a910987d-5732-48da-afeb-5e88506019c0 ==============================
[0m14:26:00.255753 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:26:00.256147 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'log_format': 'default', 'use_colors': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'quiet': 'False', 'target_path': 'None', 'invocation_command': 'dbt debug', 'warn_error': 'None', 'empty': 'None', 'indirect_selection': 'eager', 'no_print': 'None', 'printer_width': '80', 'fail_fast': 'False', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'write_json': 'True'}
[0m14:26:00.267111 [info ] [MainThread]: dbt version: 1.11.0-rc3
[0m14:26:00.267410 [info ] [MainThread]: python version: 3.12.12
[0m14:26:00.267566 [info ] [MainThread]: python path: /Users/tarik/miniconda3/envs/sp2/bin/python3.12
[0m14:26:00.267708 [info ] [MainThread]: os info: macOS-26.1-arm64-arm-64bit
[0m14:26:00.769165 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:26:00.769500 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:26:00.769670 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:26:08.956789 [info ] [MainThread]: Using profiles dir at /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project
[0m14:26:08.957329 [info ] [MainThread]: Using profiles.yml file at /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/profiles.yml
[0m14:26:08.957644 [info ] [MainThread]: Using dbt_project.yml file at /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/dbt_project.yml
[0m14:26:08.957808 [info ] [MainThread]: adapter type: databricks
[0m14:26:08.957945 [info ] [MainThread]: adapter version: 1.11.3
[0m14:26:09.014566 [info ] [MainThread]: Configuration:
[0m14:26:09.014860 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:26:09.015021 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:26:09.015154 [info ] [MainThread]: Required dependencies:
[0m14:26:09.015359 [debug] [MainThread]: Executing "git --help"
[0m14:26:09.041221 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:26:09.042164 [debug] [MainThread]: STDERR: "b''"
[0m14:26:09.042744 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:26:09.043029 [info ] [MainThread]: Connection:
[0m14:26:09.043292 [info ] [MainThread]:   host: dbc-789165f8-da9f.cloud.databricks.com
[0m14:26:09.043430 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/55eab00736b60422
[0m14:26:09.043559 [info ] [MainThread]:   catalog: patreon_dev
[0m14:26:09.043686 [info ] [MainThread]:   schema: analytics
[0m14:26:09.044061 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:26:09.141473 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:26:09.141981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a910987d-5732-48da-afeb-5e88506019c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129539b20>]}
[0m14:26:09.142393 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
[0m14:26:09.142544 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m14:26:09.142697 [debug] [MainThread]: Using databricks connection "debug"
[0m14:26:09.142842 [debug] [MainThread]: On debug: select 1 as id
[0m14:26:09.142969 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:26:09.929276 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0db75-dc03-1cdb-a43b-2f6d6a591ad1) - Created
[0m14:26:16.748682 [debug] [MainThread]: SQL status: OK in 7.600 seconds
[0m14:26:16.752526 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f0db75-dc03-1cdb-a43b-2f6d6a591ad1, command-id=01f0db75-dc2f-1404-83f6-45d6fb07662c) - Closing
[0m14:26:17.020048 [debug] [MainThread]: On debug: Close
[0m14:26:17.020793 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0db75-dc03-1cdb-a43b-2f6d6a591ad1) - Closing
[0m14:26:17.224543 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:26:17.226475 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:26:17.245432 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 17.045319, "process_in_blocks": "0", "process_kernel_time": 0.434783, "process_mem_max_rss": "255655936", "process_out_blocks": "0", "process_user_time": 2.484183}
[0m14:26:17.245898 [debug] [MainThread]: Command `dbt debug` succeeded at 14:26:17.245830 after 17.05 seconds
[0m14:26:17.246186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10627d9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ddc6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ddd580>]}
[0m14:26:17.246409 [debug] [MainThread]: Flushing usage events
[0m14:26:17.693285 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:26:25.069919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065baf60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10862b5f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10862afc0>]}


============================== 14:26:25.076427 | 59ab49b4-cdf7-4544-91e4-e395b2433a57 ==============================
[0m14:26:25.076427 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:26:25.076865 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'log_cache_events': 'False', 'warn_error': 'None', 'target_path': 'None', 'indirect_selection': 'eager', 'empty': 'False', 'debug': 'False', 'partial_parse': 'True', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'write_json': 'True', 'fail_fast': 'False', 'version_check': 'True', 'quiet': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'introspect': 'True', 'static_parser': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run'}
[0m14:26:25.570782 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:26:25.571085 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:26:25.571249 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:26:26.195720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '59ab49b4-cdf7-4544-91e4-e395b2433a57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12854a3c0>]}
[0m14:26:26.227929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '59ab49b4-cdf7-4544-91e4-e395b2433a57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f42fb30>]}
[0m14:26:26.228465 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:26:26.313547 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:26:26.314172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '59ab49b4-cdf7-4544-91e4-e395b2433a57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5f9370>]}
[0m14:26:26.314775 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found 3 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_packages. Run "dbt deps" to install package dependencies.
[0m14:26:26.317614 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.3003422, "process_in_blocks": "0", "process_kernel_time": 0.349185, "process_mem_max_rss": "250789888", "process_out_blocks": "0", "process_user_time": 2.338386}
[0m14:26:26.318199 [debug] [MainThread]: Command `dbt run` failed at 14:26:26.318143 after 1.30 seconds
[0m14:26:26.318512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10862b2f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1295da750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5c2a20>]}
[0m14:26:26.318707 [debug] [MainThread]: Flushing usage events
[0m14:26:26.613826 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:26:51.582379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1212d9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121f2eab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121f2e3f0>]}


============================== 14:26:51.586103 | d7510fbd-8b9a-4273-9911-b710d108dc51 ==============================
[0m14:26:51.586103 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:26:51.586516 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'warn_error': 'None', 'invocation_command': 'dbt seed', 'quiet': 'False', 'static_parser': 'True', 'printer_width': '80', 'use_colors': 'True', 'partial_parse': 'True', 'log_format': 'default', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'fail_fast': 'False', 'debug': 'False', 'empty': 'None', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'no_print': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'cache_selected_only': 'False', 'introspect': 'True'}
[0m14:26:52.078424 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:26:52.078778 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:26:52.078965 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:26:52.717927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd7510fbd-8b9a-4273-9911-b710d108dc51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121ecf710>]}
[0m14:26:52.750418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd7510fbd-8b9a-4273-9911-b710d108dc51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x132fac740>]}
[0m14:26:52.750971 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:26:52.840907 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:26:52.841460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'd7510fbd-8b9a-4273-9911-b710d108dc51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124791970>]}
[0m14:26:52.841948 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found 3 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_packages. Run "dbt deps" to install package dependencies.
[0m14:26:52.844872 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 1.3068702, "process_in_blocks": "0", "process_kernel_time": 0.363692, "process_mem_max_rss": "250658816", "process_out_blocks": "0", "process_user_time": 2.334977}
[0m14:26:52.845526 [debug] [MainThread]: Command `dbt seed` failed at 14:26:52.845461 after 1.31 seconds
[0m14:26:52.845938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ad2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x132ffe540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1312332c0>]}
[0m14:26:52.846231 [debug] [MainThread]: Flushing usage events
[0m14:26:53.129964 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:27:29.397396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118747200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118c10a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a26540>]}


============================== 14:27:29.401301 | 8ca71847-9fe5-4f99-8a28-be3333589e5e ==============================
[0m14:27:29.401301 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:27:29.401682 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'debug': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'invocation_command': 'dbt deps', 'version_check': 'True', 'quiet': 'False', 'use_colors': 'True', 'static_parser': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'target_path': 'None', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'no_print': 'None', 'write_json': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'warn_error': 'None', 'empty': 'None', 'introspect': 'True'}
[0m14:27:29.474690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ca71847-9fe5-4f99-8a28-be3333589e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118c10a70>]}
[0m14:27:29.490143 [debug] [MainThread]: Set downloads directory='/var/folders/17/44fmtn0931x0k_v05ghc5pl40000gn/T/dbt-downloads-elt753bd'
[0m14:27:29.490542 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:27:29.907927 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:27:29.910035 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:27:30.055401 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:27:30.065697 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json
[0m14:27:30.209448 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json 200
[0m14:27:30.212474 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `calogica/dbt_expectations` package is deprecated in favor of
`metaplane/dbt_expectations`. Please update your `packages.yml` configuration to
use `metaplane/dbt_expectations` instead.
[0m14:27:30.212936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '8ca71847-9fe5-4f99-8a28-be3333589e5e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a24200>]}
[0m14:27:30.215498 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m14:27:30.352982 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m14:27:30.354888 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json
[0m14:27:30.502430 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json 200
[0m14:27:30.520776 [info ] [MainThread]: Updating lock file in file path: /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/package-lock.yml
[0m14:27:30.524712 [debug] [MainThread]: Set downloads directory='/var/folders/17/44fmtn0931x0k_v05ghc5pl40000gn/T/dbt-downloads-4oh63jp6'
[0m14:27:30.530183 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:27:31.069436 [info ] [MainThread]: Installed from version 1.3.3
[0m14:27:31.069773 [info ] [MainThread]: Up to date!
[0m14:27:31.070028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8ca71847-9fe5-4f99-8a28-be3333589e5e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194a1280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119c2bb90>]}
[0m14:27:31.070283 [info ] [MainThread]: Installing calogica/dbt_expectations
[0m14:27:31.858801 [info ] [MainThread]: Installed from version 0.10.4
[0m14:27:31.859088 [info ] [MainThread]: Up to date!
[0m14:27:31.859294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8ca71847-9fe5-4f99-8a28-be3333589e5e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1195fa0c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bc1820>]}
[0m14:27:31.859625 [info ] [MainThread]: Installing dbt-labs/codegen
[0m14:27:32.235485 [info ] [MainThread]: Installed from version 0.14.0
[0m14:27:32.235848 [info ] [MainThread]: Up to date!
[0m14:27:32.236130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8ca71847-9fe5-4f99-8a28-be3333589e5e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b15310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119ad70e0>]}
[0m14:27:32.236427 [info ] [MainThread]: Installing calogica/dbt_date
[0m14:27:32.671818 [info ] [MainThread]: Installed from version 0.10.1
[0m14:27:32.672112 [info ] [MainThread]: Up to date!
[0m14:27:32.672331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8ca71847-9fe5-4f99-8a28-be3333589e5e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a25550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119cbb6b0>]}
[0m14:27:32.673974 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageRedirectDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:27:32.676463 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 3.3253007, "process_in_blocks": "0", "process_kernel_time": 0.32223, "process_mem_max_rss": "151126016", "process_out_blocks": "0", "process_user_time": 1.810445}
[0m14:27:32.677083 [debug] [MainThread]: Command `dbt deps` succeeded at 14:27:32.676878 after 3.33 seconds
[0m14:27:32.677529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118747200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1191f13d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119401fa0>]}
[0m14:27:32.677892 [debug] [MainThread]: Flushing usage events
[0m14:27:32.983320 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:27:48.666063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035a28a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642ac30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642a3f0>]}


============================== 14:27:48.668501 | 1c866f36-9fa8-4687-8413-babeb8b54ed1 ==============================
[0m14:27:48.668501 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:27:48.668826 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'printer_width': '80', 'fail_fast': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'write_json': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'use_colors': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'empty': 'None', 'invocation_command': 'dbt seed', 'log_format': 'default', 'introspect': 'True', 'quiet': 'False'}
[0m14:27:49.160259 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:27:49.160576 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:27:49.160751 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:27:49.816393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c866f36-9fa8-4687-8413-babeb8b54ed1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2aba70>]}
[0m14:27:49.852465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c866f36-9fa8-4687-8413-babeb8b54ed1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051b5310>]}
[0m14:27:49.852968 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:27:49.942969 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:27:49.943551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '1c866f36-9fa8-4687-8413-babeb8b54ed1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10821e450>]}
[0m14:27:49.964587 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:27:49.965189 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:27:49.965384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1c866f36-9fa8-4687-8413-babeb8b54ed1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e39b530>]}
[0m14:27:49.975260 [warn ] [MainThread]: [[33mWARNING[0m][PropertyMovedToConfigDeprecation]: Deprecated functionality
Found `meta` as a top-level property of `models[0].columns[0]` in file
`models/marts/core/schema.yml`. The `meta` top-level property should be moved
into the `config` of `models[0].columns[0]`.
[0m14:27:49.975548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '1c866f36-9fa8-4687-8413-babeb8b54ed1', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061fd760>]}
[0m14:27:51.299822 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values` defined on 'stg_creators' in
package 'patreon_analytics' (models/staging/schema.yml). Arguments to generic
tests should be nested under the `arguments` property.
[0m14:27:51.300142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '1c866f36-9fa8-4687-8413-babeb8b54ed1', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198919a0>]}
[0m14:27:51.485609 [error] [MainThread]: Encountered an error:
Parsing Error
  The semantic layer requires a time spine model with granularity DAY or smaller in the project, but none was found. Guidance on creating this model can be found on our docs site (https://docs.getdbt.com/docs/build/metricflow-time-spine).
[0m14:27:51.486060 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PropertyMovedToConfigDeprecation: 42 occurrences
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:27:51.488875 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 2.8639047, "process_in_blocks": "0", "process_kernel_time": 0.400773, "process_mem_max_rss": "267272192", "process_out_blocks": "0", "process_user_time": 3.737272}
[0m14:27:51.489380 [debug] [MainThread]: Command `dbt seed` failed at 14:27:51.489323 after 2.86 seconds
[0m14:27:51.489637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1007a2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104aadd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118793110>]}
[0m14:27:51.489832 [debug] [MainThread]: Flushing usage events
[0m14:27:51.850737 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:34:26.670006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144cf290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11462ea50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11462e0f0>]}


============================== 14:34:26.673718 | d2ccd821-f5c7-4e7d-a010-10f10feb6e0c ==============================
[0m14:34:26.673718 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:34:26.674127 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'debug': 'False', 'write_json': 'True', 'empty': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'cache_selected_only': 'False', 'version_check': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'no_print': 'None', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'introspect': 'True', 'warn_error': 'None', 'printer_width': '80', 'invocation_command': 'dbt deps', 'partial_parse': 'True', 'log_format': 'default'}
[0m14:34:26.771208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2ccd821-f5c7-4e7d-a010-10f10feb6e0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109439b0>]}
[0m14:34:26.850786 [debug] [MainThread]: Set downloads directory='/var/folders/17/44fmtn0931x0k_v05ghc5pl40000gn/T/dbt-downloads-gz6d0xv6'
[0m14:34:26.851100 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:34:27.120735 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:34:27.122221 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:34:27.264874 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:34:27.268314 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json
[0m14:34:27.439323 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json 200
[0m14:34:27.441755 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `calogica/dbt_expectations` package is deprecated in favor of
`metaplane/dbt_expectations`. Please update your `packages.yml` configuration to
use `metaplane/dbt_expectations` instead.
[0m14:34:27.442117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'd2ccd821-f5c7-4e7d-a010-10f10feb6e0c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f793a0>]}
[0m14:34:27.443470 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m14:34:27.583320 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m14:34:27.584979 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json
[0m14:34:27.790647 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json 200
[0m14:34:27.793016 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:34:28.300296 [info ] [MainThread]: Installed from version 1.3.3
[0m14:34:28.300585 [info ] [MainThread]: Up to date!
[0m14:34:28.300795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd2ccd821-f5c7-4e7d-a010-10f10feb6e0c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140e3ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11462c620>]}
[0m14:34:28.301024 [info ] [MainThread]: Installing calogica/dbt_expectations
[0m14:34:29.257888 [info ] [MainThread]: Installed from version 0.10.4
[0m14:34:29.258181 [info ] [MainThread]: Up to date!
[0m14:34:29.258385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd2ccd821-f5c7-4e7d-a010-10f10feb6e0c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148bf050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148bf1a0>]}
[0m14:34:29.258602 [info ] [MainThread]: Installing dbt-labs/codegen
[0m14:34:29.558254 [info ] [MainThread]: Installed from version 0.14.0
[0m14:34:29.558587 [info ] [MainThread]: Up to date!
[0m14:34:29.558818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd2ccd821-f5c7-4e7d-a010-10f10feb6e0c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113201070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113202570>]}
[0m14:34:29.559070 [info ] [MainThread]: Installing calogica/dbt_date
[0m14:34:29.934029 [info ] [MainThread]: Installed from version 0.10.1
[0m14:34:29.934319 [info ] [MainThread]: Up to date!
[0m14:34:29.934524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd2ccd821-f5c7-4e7d-a010-10f10feb6e0c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148bf830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148bf170>]}
[0m14:34:29.935847 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageRedirectDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:34:29.938289 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 3.3128986, "process_in_blocks": "0", "process_kernel_time": 0.350618, "process_mem_max_rss": "149602304", "process_out_blocks": "0", "process_user_time": 1.722269}
[0m14:34:29.938700 [debug] [MainThread]: Command `dbt deps` succeeded at 14:34:29.938640 after 3.31 seconds
[0m14:34:29.938918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10321f050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fa1850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1146e5130>]}
[0m14:34:29.939130 [debug] [MainThread]: Flushing usage events
[0m14:34:30.348744 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:34:32.268290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132da7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114434f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144346e0>]}


============================== 14:34:32.271375 | 712f75bb-a410-4074-890a-b97308f56d9c ==============================
[0m14:34:32.271375 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:34:32.271705 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'fail_fast': 'False', 'quiet': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'debug': 'False', 'log_format': 'default', 'no_print': 'None', 'warn_error': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'invocation_command': 'dbt seed', 'write_json': 'True', 'empty': 'None', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'indirect_selection': 'eager'}
[0m14:34:32.275306 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'DATABRICKS_HOST'
[0m14:34:32.276868 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 0.048020832, "process_in_blocks": "0", "process_kernel_time": 0.14973, "process_mem_max_rss": "132448256", "process_out_blocks": "0", "process_user_time": 1.336745}
[0m14:34:32.277212 [debug] [MainThread]: Command `dbt seed` failed at 14:34:32.277163 after 0.05 seconds
[0m14:34:32.277412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114434b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114437620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c91dc0>]}
[0m14:34:32.277592 [debug] [MainThread]: Flushing usage events
[0m14:34:32.556008 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:35:17.954665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11437f980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b35be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b35550>]}


============================== 14:35:17.958390 | 84e0b9a7-3625-4ad4-baed-09f58dd259f3 ==============================
[0m14:35:17.958390 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:35:17.958749 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'log_format': 'default', 'use_colors': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'introspect': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'invocation_command': 'dbt deps', 'version_check': 'True', 'empty': 'None', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs'}
[0m14:35:18.055694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '84e0b9a7-3625-4ad4-baed-09f58dd259f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114bd5b20>]}
[0m14:35:18.121887 [debug] [MainThread]: Set downloads directory='/var/folders/17/44fmtn0931x0k_v05ghc5pl40000gn/T/dbt-downloads-keczho6r'
[0m14:35:18.122243 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:35:18.268014 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:35:18.269034 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:35:18.488696 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:35:18.492628 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json
[0m14:35:18.659069 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json 200
[0m14:35:18.661125 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `calogica/dbt_expectations` package is deprecated in favor of
`metaplane/dbt_expectations`. Please update your `packages.yml` configuration to
use `metaplane/dbt_expectations` instead.
[0m14:35:18.661432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '84e0b9a7-3625-4ad4-baed-09f58dd259f3', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b0b560>]}
[0m14:35:18.663012 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m14:35:18.907950 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m14:35:18.909736 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json
[0m14:35:19.082749 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json 200
[0m14:35:19.084589 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:35:19.562187 [info ] [MainThread]: Installed from version 1.3.3
[0m14:35:19.562491 [info ] [MainThread]: Up to date!
[0m14:35:19.562710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '84e0b9a7-3625-4ad4-baed-09f58dd259f3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e8bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114eb2420>]}
[0m14:35:19.562936 [info ] [MainThread]: Installing calogica/dbt_expectations
[0m14:35:20.306735 [info ] [MainThread]: Installed from version 0.10.4
[0m14:35:20.307000 [info ] [MainThread]: Up to date!
[0m14:35:20.307190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '84e0b9a7-3625-4ad4-baed-09f58dd259f3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c1b440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c19220>]}
[0m14:35:20.307388 [info ] [MainThread]: Installing dbt-labs/codegen
[0m14:35:20.768133 [info ] [MainThread]: Installed from version 0.14.0
[0m14:35:20.768452 [info ] [MainThread]: Up to date!
[0m14:35:20.768675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '84e0b9a7-3625-4ad4-baed-09f58dd259f3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e371a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e37050>]}
[0m14:35:20.768915 [info ] [MainThread]: Installing calogica/dbt_date
[0m14:35:21.181472 [info ] [MainThread]: Installed from version 0.10.1
[0m14:35:21.181770 [info ] [MainThread]: Up to date!
[0m14:35:21.181968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '84e0b9a7-3625-4ad4-baed-09f58dd259f3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114bd4680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114bd5df0>]}
[0m14:35:21.183229 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageRedirectDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:35:21.185225 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 3.2746265, "process_in_blocks": "0", "process_kernel_time": 0.343906, "process_mem_max_rss": "149028864", "process_out_blocks": "0", "process_user_time": 1.725064}
[0m14:35:21.185566 [debug] [MainThread]: Command `dbt deps` succeeded at 14:35:21.185506 after 3.28 seconds
[0m14:35:21.185801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113cd91c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b0b560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11189f200>]}
[0m14:35:21.186009 [debug] [MainThread]: Flushing usage events
[0m14:35:21.527539 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:35:23.318018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069fd640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f2ecc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f2e5a0>]}


============================== 14:35:23.320842 | b0051998-d266-4201-8692-087d981e1a08 ==============================
[0m14:35:23.320842 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:35:23.321184 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'target_path': 'None', 'write_json': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'invocation_command': 'dbt seed', 'log_format': 'default', 'cache_selected_only': 'False', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'quiet': 'False', 'no_print': 'None', 'static_parser': 'True', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80'}
[0m14:35:23.807824 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:35:23.808182 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:35:23.808370 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:35:24.496659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0051998-d266-4201-8692-087d981e1a08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1196ffc80>]}
[0m14:35:24.532130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b0051998-d266-4201-8692-087d981e1a08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11915ddf0>]}
[0m14:35:24.532637 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:35:24.620846 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:35:24.621429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'b0051998-d266-4201-8692-087d981e1a08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e28500>]}
[0m14:35:24.638692 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:35:24.639244 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:35:24.639432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b0051998-d266-4201-8692-087d981e1a08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11967a2d0>]}
[0m14:35:24.648986 [warn ] [MainThread]: [[33mWARNING[0m][PropertyMovedToConfigDeprecation]: Deprecated functionality
Found `meta` as a top-level property of `models[0].columns[0]` in file
`models/marts/core/schema.yml`. The `meta` top-level property should be moved
into the `config` of `models[0].columns[0]`.
[0m14:35:24.649318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b0051998-d266-4201-8692-087d981e1a08', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11978ba40>]}
[0m14:35:25.941068 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values` defined on 'stg_creators' in
package 'patreon_analytics' (models/staging/schema.yml). Arguments to generic
tests should be nested under the `arguments` property.
[0m14:35:25.941424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b0051998-d266-4201-8692-087d981e1a08', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a2fdd60>]}
[0m14:35:26.123483 [error] [MainThread]: Encountered an error:
Parsing Error
  The semantic layer requires a time spine model with granularity DAY or smaller in the project, but none was found. Guidance on creating this model can be found on our docs site (https://docs.getdbt.com/docs/build/metricflow-time-spine).
[0m14:35:26.123951 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PropertyMovedToConfigDeprecation: 42 occurrences
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:35:26.126375 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 2.8481545, "process_in_blocks": "0", "process_kernel_time": 0.367117, "process_mem_max_rss": "268124160", "process_out_blocks": "0", "process_user_time": 3.660052}
[0m14:35:26.126744 [debug] [MainThread]: Command `dbt seed` failed at 14:35:26.126697 after 2.85 seconds
[0m14:35:26.126977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1008af080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a376240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a2b2900>]}
[0m14:35:26.127164 [debug] [MainThread]: Flushing usage events
[0m14:35:26.468404 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:36:50.107815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100fdca70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b66f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b5f40>]}


============================== 14:36:50.112532 | 3cb6abf9-ecb1-4de7-b489-55e87d675e3a ==============================
[0m14:36:50.112532 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:36:50.112996 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'introspect': 'True', 'warn_error': 'None', 'no_print': 'None', 'debug': 'False', 'fail_fast': 'False', 'version_check': 'True', 'write_json': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt deps', 'log_format': 'default', 'empty': 'None', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'target_path': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'quiet': 'False'}
[0m14:36:50.241304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3cb6abf9-ecb1-4de7-b489-55e87d675e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a6a0c0>]}
[0m14:36:50.320595 [debug] [MainThread]: Set downloads directory='/var/folders/17/44fmtn0931x0k_v05ghc5pl40000gn/T/dbt-downloads-tmhxfcka'
[0m14:36:50.320906 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:36:50.591793 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:36:50.592988 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:36:50.815177 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:36:50.818953 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json
[0m14:36:50.961154 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json 200
[0m14:36:50.963515 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `calogica/dbt_expectations` package is deprecated in favor of
`metaplane/dbt_expectations`. Please update your `packages.yml` configuration to
use `metaplane/dbt_expectations` instead.
[0m14:36:50.963935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '3cb6abf9-ecb1-4de7-b489-55e87d675e3a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105af8c20>]}
[0m14:36:50.965622 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m14:36:51.126382 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m14:36:51.128084 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json
[0m14:36:51.372450 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json 200
[0m14:36:51.374418 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:36:52.147665 [info ] [MainThread]: Installed from version 1.3.3
[0m14:36:52.147973 [info ] [MainThread]: Up to date!
[0m14:36:52.148195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '3cb6abf9-ecb1-4de7-b489-55e87d675e3a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d8bf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a59490>]}
[0m14:36:52.148443 [info ] [MainThread]: Installing calogica/dbt_expectations
[0m14:36:53.408823 [info ] [MainThread]: Installed from version 0.10.4
[0m14:36:53.409112 [info ] [MainThread]: Up to date!
[0m14:36:53.409323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '3cb6abf9-ecb1-4de7-b489-55e87d675e3a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d36b40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d36e10>]}
[0m14:36:53.409558 [info ] [MainThread]: Installing dbt-labs/codegen
[0m14:36:53.703266 [info ] [MainThread]: Installed from version 0.14.0
[0m14:36:53.703552 [info ] [MainThread]: Up to date!
[0m14:36:53.703759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '3cb6abf9-ecb1-4de7-b489-55e87d675e3a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dbe330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dbe180>]}
[0m14:36:53.703977 [info ] [MainThread]: Installing calogica/dbt_date
[0m14:36:56.143630 [info ] [MainThread]: Installed from version 0.10.1
[0m14:36:56.144033 [info ] [MainThread]: Up to date!
[0m14:36:56.144331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '3cb6abf9-ecb1-4de7-b489-55e87d675e3a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dbdee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dbe360>]}
[0m14:36:56.145999 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageRedirectDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:36:56.148705 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.0978827, "process_in_blocks": "0", "process_kernel_time": 0.374734, "process_mem_max_rss": "149618688", "process_out_blocks": "0", "process_user_time": 1.778868}
[0m14:36:56.149199 [debug] [MainThread]: Command `dbt deps` succeeded at 14:36:56.149120 after 6.10 seconds
[0m14:36:56.149496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a596d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105256cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b6c590>]}
[0m14:36:56.149770 [debug] [MainThread]: Flushing usage events
[0m14:36:56.475306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:36:58.309504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065c5760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107032a80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070323f0>]}


============================== 14:36:58.312171 | 90506413-25f7-4dee-827e-8e24c84ad52a ==============================
[0m14:36:58.312171 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:36:58.312525 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'partial_parse': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'quiet': 'False', 'fail_fast': 'False', 'invocation_command': 'dbt seed', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'write_json': 'True', 'target_path': 'None', 'printer_width': '80', 'no_print': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'warn_error': 'None'}
[0m14:36:58.792114 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:36:58.792468 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:36:58.792651 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:36:59.417939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90506413-25f7-4dee-827e-8e24c84ad52a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f21e930>]}
[0m14:36:59.448352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90506413-25f7-4dee-827e-8e24c84ad52a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119272c30>]}
[0m14:36:59.448824 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:36:59.532838 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:36:59.533395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '90506413-25f7-4dee-827e-8e24c84ad52a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192d3d40>]}
[0m14:36:59.551300 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:36:59.551822 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:36:59.552042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '90506413-25f7-4dee-827e-8e24c84ad52a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ba42c0>]}
[0m14:36:59.562092 [warn ] [MainThread]: [[33mWARNING[0m][PropertyMovedToConfigDeprecation]: Deprecated functionality
Found `meta` as a top-level property of `models[0].columns[0]` in file
`models/marts/core/schema.yml`. The `meta` top-level property should be moved
into the `config` of `models[0].columns[0]`.
[0m14:36:59.562440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '90506413-25f7-4dee-827e-8e24c84ad52a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1195f4bf0>]}
[0m14:37:00.922973 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values` defined on 'stg_creators' in
package 'patreon_analytics' (models/staging/schema.yml). Arguments to generic
tests should be nested under the `arguments` property.
[0m14:37:00.923323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '90506413-25f7-4dee-827e-8e24c84ad52a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b129cd0>]}
[0m14:37:01.059733 [error] [MainThread]: Encountered an error:
Parsing Error
  Time spine standard granularity column must be defined on the model. Got invalid column name 'date_day' for model 'metricflow_time_spine'. Valid names: [].
[0m14:37:01.060156 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PropertyMovedToConfigDeprecation: 42 occurrences
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:37:01.062684 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 2.7907476, "process_in_blocks": "0", "process_kernel_time": 0.364968, "process_mem_max_rss": "265076736", "process_out_blocks": "0", "process_user_time": 3.638436}
[0m14:37:01.063132 [debug] [MainThread]: Command `dbt seed` failed at 14:37:01.063073 after 2.79 seconds
[0m14:37:01.063414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b00ef90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a7a9a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b05f350>]}
[0m14:37:01.063636 [debug] [MainThread]: Flushing usage events
[0m14:37:01.406544 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:37:43.875248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2e5b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b32acf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b32a5a0>]}


============================== 14:37:43.878533 | 0b82fc3c-08c3-4284-9e63-3f1f987eaefb ==============================
[0m14:37:43.878533 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:37:43.878887 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'write_json': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'warn_error': 'None', 'invocation_command': 'dbt seed', 'static_parser': 'True', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'introspect': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'quiet': 'False', 'fail_fast': 'False', 'empty': 'None', 'printer_width': '80', 'target_path': 'None', 'no_print': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'send_anonymous_usage_stats': 'True'}
[0m14:37:44.356555 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:37:44.356894 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:37:44.357071 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:37:44.992983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0b82fc3c-08c3-4284-9e63-3f1f987eaefb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d3afbc0>]}
[0m14:37:45.025052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0b82fc3c-08c3-4284-9e63-3f1f987eaefb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cecc620>]}
[0m14:37:45.025550 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:37:45.115182 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:37:45.115775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '0b82fc3c-08c3-4284-9e63-3f1f987eaefb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d477d40>]}
[0m14:37:45.135017 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:37:45.135630 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:37:45.135845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0b82fc3c-08c3-4284-9e63-3f1f987eaefb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d3814f0>]}
[0m14:37:45.145853 [warn ] [MainThread]: [[33mWARNING[0m][PropertyMovedToConfigDeprecation]: Deprecated functionality
Found `meta` as a top-level property of `models[0].columns[0]` in file
`models/marts/core/schema.yml`. The `meta` top-level property should be moved
into the `config` of `models[0].columns[0]`.
[0m14:37:45.146249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0b82fc3c-08c3-4284-9e63-3f1f987eaefb', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d70dcd0>]}
[0m14:37:46.527950 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values` defined on 'stg_creators' in
package 'patreon_analytics' (models/staging/schema.yml). Arguments to generic
tests should be nested under the `arguments` property.
[0m14:37:46.528285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0b82fc3c-08c3-4284-9e63-3f1f987eaefb', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11deade80>]}
[0m14:37:46.716553 [error] [MainThread]: No input metrics found for derived metric 'platform_take_rate'. Please add metrics to type_params.metrics.
[0m14:37:46.716859 [error] [MainThread]: Invalid name `month` - names cannot match reserved time granularity keywords (['NANOSECOND', 'MICROSECOND', 'MILLISECOND', 'SECOND', 'MINUTE', 'HOUR', 'DAY', 'WEEK', 'MONTH', 'QUARTER', 'YEAR'])
[0m14:37:46.717026 [error] [MainThread]: An error occurred while checking aggregation time dimension for a semantic model - AssertionError: Aggregation time dimension for measure mrr is not set! This should either be set directly on the measure specification in the model, or else defaulted to the primary time dimension in the data source containing the measure.

[0m14:37:46.717217 [error] [MainThread]: Encountered an error:
Parsing Error
  Semantic Manifest validation failed.
[0m14:37:46.717509 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PropertyMovedToConfigDeprecation: 42 occurrences
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:37:46.720659 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 2.885322, "process_in_blocks": "0", "process_kernel_time": 0.394348, "process_mem_max_rss": "268009472", "process_out_blocks": "0", "process_user_time": 3.759682}
[0m14:37:46.721080 [debug] [MainThread]: Command `dbt seed` failed at 14:37:46.721033 after 2.89 seconds
[0m14:37:46.721346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102acb080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11df76120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11df6caa0>]}
[0m14:37:46.721560 [debug] [MainThread]: Flushing usage events
[0m14:37:47.206193 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:38:44.276225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10839bb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b48ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b481d0>]}


============================== 14:38:44.279571 | 300d5257-699e-41d0-9d25-1591df791008 ==============================
[0m14:38:44.279571 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:38:44.279919 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'no_print': 'None', 'static_parser': 'True', 'debug': 'False', 'warn_error': 'None', 'invocation_command': 'dbt seed', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'empty': 'None', 'log_format': 'default', 'fail_fast': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'use_colors': 'True', 'write_json': 'True', 'target_path': 'None', 'partial_parse': 'True', 'quiet': 'False', 'cache_selected_only': 'False'}
[0m14:38:44.758585 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:38:44.758925 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:38:44.759106 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:38:45.423661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b924950>]}
[0m14:38:45.455756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc63b30>]}
[0m14:38:45.456260 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:38:45.542010 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:38:45.542609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c7f3c20>]}
[0m14:38:45.563791 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:38:45.564422 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:38:45.564639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c79ad50>]}
[0m14:38:45.573756 [warn ] [MainThread]: [[33mWARNING[0m][PropertyMovedToConfigDeprecation]: Deprecated functionality
Found `meta` as a top-level property of `models[0].columns[0]` in file
`models/marts/core/schema.yml`. The `meta` top-level property should be moved
into the `config` of `models[0].columns[0]`.
[0m14:38:45.574075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb02150>]}
[0m14:38:46.936915 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values` defined on 'stg_creators' in
package 'patreon_analytics' (models/staging/schema.yml). Arguments to generic
tests should be nested under the `arguments` property.
[0m14:38:46.937239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d2aa0f0>]}
[0m14:38:47.163834 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.patreon_analytics.intermediate
- models.patreon_analytics.marts.finance
[0m14:38:47.168022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d2fca70>]}
[0m14:38:47.242796 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:38:47.245263 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:38:47.256679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cec77d0>]}
[0m14:38:47.257038 [info ] [MainThread]: Found 9 models, 7 seeds, 36 data tests, 4 metrics, 1125 macros, 1 semantic model
[0m14:38:47.257240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '300d5257-699e-41d0-9d25-1591df791008', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cdb2540>]}
[0m14:38:47.258745 [info ] [MainThread]: 
[0m14:38:47.258989 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:38:47.259143 [info ] [MainThread]: 
[0m14:38:47.259436 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:38:47.259593 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:38:47.263298 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev) - Creating connection
[0m14:38:47.263552 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev'
[0m14:38:47.267827 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev"
[0m14:38:47.268056 [debug] [ThreadPool]: On list_patreon_dev: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
[0m14:38:47.268210 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:38:48.635370 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-a030-16a8-ab9c-3f640eae739e) - Created
[0m14:38:54.718232 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'patreon_dev' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [NO_SUCH_CATALOG_EXCEPTION] org.apache.spark.sql.catalyst.analysis.NoSuchCatalogException: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'patreon_dev' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1050)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:787)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:578)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:869)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:578)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:62)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:89)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:108)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:216)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:555)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:541)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:591)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.analysis.NoSuchCatalogException: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'patreon_dev' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.$anonfun$listSchemasProto$1(ManagedCatalogClientImpl.scala:1389)
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$2(ManagedCatalogClientImpl.scala:7997)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:145)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$1(ManagedCatalogClientImpl.scala:7996)
	at com.databricks.sql.managedcatalog.client.ErrorDetailsHandlerImpl.wrapServiceException(ErrorDetailsHandler.scala:96)
	at com.databricks.sql.managedcatalog.client.ErrorDetailsHandlerImpl.wrapServiceException$(ErrorDetailsHandler.scala:88)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:44)
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7975)
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7959)
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.listSchemasProto(ManagedCatalogClientImpl.scala:1355)
	at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.listSchemas(ManagedCatalogClientImpl.scala:1338)
	at com.databricks.sql.managedcatalog.ManagedCatalogCommon.listSchemas(ManagedCatalogCommon.scala:892)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$listSchemas$1(ProfiledManagedCatalog.scala:196)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:2144)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:74)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:145)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:73)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.listSchemas(ProfiledManagedCatalog.scala:196)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.listDatabasesWithCatalog(ManagedCatalogSessionCatalog.scala:1108)
	at com.databricks.sql.managedcatalog.UnityCatalogV2Proxy.listNamespaces(UnityCatalogV2Proxy.scala:141)
	at org.apache.spark.sql.execution.command.ShowNamespacesCommand.run(ShowNamespacesCommand.scala:56)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:87)
	at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:195)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:87)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:198)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:84)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:83)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:97)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:596)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:596)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:265)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:595)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$18(SQLExecution.scala:600)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$16(SQLExecution.scala:513)
	at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:932)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$15(SQLExecution.scala:434)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
	at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:124)
	at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:118)
	at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:123)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$14(SQLExecution.scala:434)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:967)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:433)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:255)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:885)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:591)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1607)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:587)
	at org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:528)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:585)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:702)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:694)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:543)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:543)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:45)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:45)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:45)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:519)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:694)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:694)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:484)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:489)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:431)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:411)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$analyzeQuery$2(SparkExecuteStatementOperation.scala:782)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$analyzeQuery$1(SparkExecuteStatementOperation.scala:701)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:687)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:701)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:847)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:583)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:847)
	... 53 more
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.$anonfun$listSchemasProto$1(ManagedCatalogClientImpl.scala:1389)
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$2(ManagedCatalogClientImpl.scala:7997)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:145)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$1(ManagedCatalogClientImpl.scala:7996)
		at com.databricks.sql.managedcatalog.client.ErrorDetailsHandlerImpl.wrapServiceException(ErrorDetailsHandler.scala:96)
		at com.databricks.sql.managedcatalog.client.ErrorDetailsHandlerImpl.wrapServiceException$(ErrorDetailsHandler.scala:88)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:44)
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7975)
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7959)
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.listSchemasProto(ManagedCatalogClientImpl.scala:1355)
		at com.databricks.sql.managedcatalog.client.ManagedCatalogClientImpl.listSchemas(ManagedCatalogClientImpl.scala:1338)
		at com.databricks.sql.managedcatalog.ManagedCatalogCommon.listSchemas(ManagedCatalogCommon.scala:892)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$listSchemas$1(ProfiledManagedCatalog.scala:196)
		at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:2144)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:74)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:145)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:73)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.listSchemas(ProfiledManagedCatalog.scala:196)
		at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.listDatabasesWithCatalog(ManagedCatalogSessionCatalog.scala:1108)
		at com.databricks.sql.managedcatalog.UnityCatalogV2Proxy.listNamespaces(UnityCatalogV2Proxy.scala:141)
		at org.apache.spark.sql.execution.command.ShowNamespacesCommand.run(ShowNamespacesCommand.scala:56)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:87)
		at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:195)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:87)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:198)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:84)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:83)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:97)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:596)
		at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:596)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:265)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:595)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$18(SQLExecution.scala:600)
		at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$16(SQLExecution.scala:513)
		at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:932)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$15(SQLExecution.scala:434)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
		at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:124)
		at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:118)
		at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:123)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$14(SQLExecution.scala:434)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:967)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:433)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:255)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:885)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:591)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1607)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:587)
		at org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:528)
		at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:585)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:702)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:694)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:543)
		at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:543)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:45)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:45)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:45)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:519)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:694)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)
		at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:694)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:484)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		... 65 more
, operation-id=01f0db77-a067-1bf2-8244-d44a6939bb43
[0m14:38:54.720701 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
macro list_schemas
: Database Error
  [NO_SUCH_CATALOG_EXCEPTION] Catalog 'patreon_dev' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
[0m14:38:54.721241 [debug] [ThreadPool]: On list_patreon_dev: Close
[0m14:38:54.721558 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-a030-16a8-ab9c-3f640eae739e) - Closing
[0m14:38:54.927182 [info ] [MainThread]: 
[0m14:38:54.927486 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 7.67 seconds (7.67s).
[0m14:38:54.927754 [error] [MainThread]: Encountered an error:
Database Error
  Database Error
    [NO_SUCH_CATALOG_EXCEPTION] Catalog 'patreon_dev' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
[0m14:38:54.928084 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PropertyMovedToConfigDeprecation: 42 occurrences
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:38:54.932651 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 10.697953, "process_in_blocks": "0", "process_kernel_time": 0.413898, "process_mem_max_rss": "275644416", "process_out_blocks": "0", "process_user_time": 3.96183}
[0m14:38:54.933195 [debug] [MainThread]: Command `dbt seed` failed at 14:38:54.933142 after 10.70 seconds
[0m14:38:54.933420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d282510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cff8e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cff8e00>]}
[0m14:38:54.933620 [debug] [MainThread]: Flushing usage events
[0m14:38:55.232569 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:39:35.682993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10596a510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10702a960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10702a1e0>]}


============================== 14:39:35.686354 | 69bafaa9-c75f-47d7-ae00-6233649724bc ==============================
[0m14:39:35.686354 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:39:35.686696 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'static_parser': 'True', 'log_format': 'default', 'write_json': 'True', 'empty': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'invocation_command': 'dbt run-operation --args {"sql": "CREATE CATALOG IF NOT EXISTS patreon_dev"} run_query', 'indirect_selection': 'eager', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'warn_error': 'None', 'introspect': 'True', 'fail_fast': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'use_colors': 'True', 'debug': 'False'}
[0m14:39:36.172621 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:39:36.172973 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:39:36.173151 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:39:36.815986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69bafaa9-c75f-47d7-ae00-6233649724bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ff530>]}
[0m14:39:36.850943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69bafaa9-c75f-47d7-ae00-6233649724bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106554620>]}
[0m14:39:36.851453 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:39:36.942058 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:39:36.942628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '69bafaa9-c75f-47d7-ae00-6233649724bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x131061340>]}
[0m14:39:36.962740 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:39:37.099980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:39:37.100302 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m14:39:37.100445 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:39:37.105374 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.patreon_analytics.marts.finance
- models.patreon_analytics.intermediate
[0m14:39:37.137063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69bafaa9-c75f-47d7-ae00-6233649724bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1314c6db0>]}
[0m14:39:37.209493 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:39:37.212333 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:39:37.219420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69bafaa9-c75f-47d7-ae00-6233649724bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x131851a30>]}
[0m14:39:37.219738 [info ] [MainThread]: Found 9 models, 7 seeds, 36 data tests, 4 metrics, 1125 macros, 1 semantic model
[0m14:39:37.219931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69bafaa9-c75f-47d7-ae00-6233649724bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111069460>]}
[0m14:39:37.220294 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=macro_run_query) - Creating connection
[0m14:39:37.220464 [debug] [MainThread]: Acquiring new databricks connection 'macro_run_query'
[0m14:39:37.226286 [debug] [MainThread]: Using databricks connection "macro_run_query"
[0m14:39:37.226572 [debug] [MainThread]: On macro_run_query: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "macro_run_query"} */

    CREATE CATALOG IF NOT EXISTS patreon_dev
  
[0m14:39:37.226735 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:39:37.855345 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0db77-bda4-1815-a562-24001e9eea5c) - Created
[0m14:39:39.344826 [debug] [MainThread]: SQL status: OK in 2.120 seconds
[0m14:39:39.352214 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f0db77-bda4-1815-a562-24001e9eea5c, command-id=01f0db77-bdbe-106c-8d62-58519da269f2) - Closing
[0m14:39:39.352640 [debug] [MainThread]: On macro_run_query: Close
[0m14:39:39.352888 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0db77-bda4-1815-a562-24001e9eea5c) - Closing
[0m14:39:39.535797 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/run_results.json
[0m14:39:39.541566 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 3.9000962, "process_in_blocks": "0", "process_kernel_time": 0.403276, "process_mem_max_rss": "270254080", "process_out_blocks": "0", "process_user_time": 2.568727}
[0m14:39:39.542261 [debug] [MainThread]: Command `dbt run-operation` succeeded at 14:39:39.542150 after 3.90 seconds
[0m14:39:39.542719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10148f0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10596a510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10702a960>]}
[0m14:39:39.543111 [debug] [MainThread]: Flushing usage events
[0m14:39:39.992312 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:40:17.394268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f6a600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11342aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11342a5d0>]}


============================== 14:40:17.397706 | d4c596a6-af71-41af-81e6-95d3d581253c ==============================
[0m14:40:17.397706 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:40:17.398078 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'partial_parse': 'True', 'printer_width': '80', 'invocation_command': 'dbt run-operation create_catalog --args {"catalog_name": "patreon_dev"}', 'no_print': 'None', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'use_experimental_parser': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'static_parser': 'True', 'empty': 'None', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'log_cache_events': 'False'}
[0m14:40:17.914098 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:40:17.914420 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:40:17.914590 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:40:18.582908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd4c596a6-af71-41af-81e6-95d3d581253c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x134f6f4a0>]}
[0m14:40:18.617235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd4c596a6-af71-41af-81e6-95d3d581253c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133da71a0>]}
[0m14:40:18.617756 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:40:18.703602 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:40:18.704119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'd4c596a6-af71-41af-81e6-95d3d581253c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136c670b0>]}
[0m14:40:18.724833 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:40:18.866215 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:40:18.866689 [debug] [MainThread]: Partial parsing: added file: patreon_analytics://macros/create_catalog.sql
[0m14:40:18.932515 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.patreon_analytics.intermediate
- models.patreon_analytics.marts.finance
[0m14:40:18.936352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd4c596a6-af71-41af-81e6-95d3d581253c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a5fad0>]}
[0m14:40:19.009924 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:40:19.012227 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:40:19.019304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd4c596a6-af71-41af-81e6-95d3d581253c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13766d520>]}
[0m14:40:19.019652 [info ] [MainThread]: Found 9 models, 7 seeds, 36 data tests, 4 metrics, 1126 macros, 1 semantic model
[0m14:40:19.019854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd4c596a6-af71-41af-81e6-95d3d581253c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117f8e9c0>]}
[0m14:40:19.020242 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=macro_create_catalog) - Creating connection
[0m14:40:19.020407 [debug] [MainThread]: Acquiring new databricks connection 'macro_create_catalog'
[0m14:40:19.026905 [debug] [MainThread]: Using databricks connection "macro_create_catalog"
[0m14:40:19.027161 [debug] [MainThread]: On macro_create_catalog: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "macro_create_catalog"} */

    
        CREATE CATALOG IF NOT EXISTS patreon_dev
    
  
[0m14:40:19.027326 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:40:19.662318 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0db77-d68b-1267-9c04-8f9e0f0e259a) - Created
[0m14:40:20.164716 [debug] [MainThread]: SQL status: OK in 1.140 seconds
[0m14:40:20.168200 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f0db77-d68b-1267-9c04-8f9e0f0e259a, command-id=01f0db77-d6a9-13fe-bf12-75a369f318a4) - Closing
[0m14:40:20.168477 [info ] [MainThread]: Catalog patreon_dev created or already exists
[0m14:40:20.168731 [debug] [MainThread]: On macro_create_catalog: Close
[0m14:40:20.168892 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0db77-d68b-1267-9c04-8f9e0f0e259a) - Closing
[0m14:40:20.363162 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/run_results.json
[0m14:40:20.366195 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 3.014988, "process_in_blocks": "0", "process_kernel_time": 0.402127, "process_mem_max_rss": "270155776", "process_out_blocks": "0", "process_user_time": 2.596371}
[0m14:40:20.366529 [debug] [MainThread]: Command `dbt run-operation` succeeded at 14:40:20.366469 after 3.02 seconds
[0m14:40:20.366767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10323b0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117a5160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11342aed0>]}
[0m14:40:20.366975 [debug] [MainThread]: Flushing usage events
[0m14:40:20.659402 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:40:32.439248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2b9d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd2b620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd2af00>]}


============================== 14:40:32.442355 | ffb9479b-238a-4a4f-9e5d-51b4027e3978 ==============================
[0m14:40:32.442355 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:40:32.442700 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'write_json': 'True', 'invocation_command': 'dbt seed', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'debug': 'False', 'target_path': 'None', 'static_parser': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'warn_error': 'None', 'introspect': 'True', 'partial_parse': 'True', 'quiet': 'False'}
[0m14:40:32.905955 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:40:32.906289 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:40:32.906461 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:40:33.538646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d0797f0>]}
[0m14:40:33.571091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de66960>]}
[0m14:40:33.571615 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:40:33.663128 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:40:33.663727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d0a49b0>]}
[0m14:40:33.684266 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:40:33.816214 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:40:33.816546 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m14:40:33.816701 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:40:33.821298 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.patreon_analytics.marts.finance
- models.patreon_analytics.intermediate
[0m14:40:33.852189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d30d4f0>]}
[0m14:40:33.923002 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:40:33.925857 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:40:33.935076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d800b30>]}
[0m14:40:33.935387 [info ] [MainThread]: Found 9 models, 7 seeds, 36 data tests, 4 metrics, 1126 macros, 1 semantic model
[0m14:40:33.935567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d85ac90>]}
[0m14:40:33.936933 [info ] [MainThread]: 
[0m14:40:33.937109 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:40:33.937243 [info ] [MainThread]: 
[0m14:40:33.937538 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:40:33.937683 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:40:33.940919 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev) - Creating connection
[0m14:40:33.941218 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev'
[0m14:40:33.949284 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev"
[0m14:40:33.949577 [debug] [ThreadPool]: On list_patreon_dev: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
[0m14:40:33.949758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:34.570493 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-df71-1037-acf2-d56ff4dfbc6d) - Created
[0m14:40:35.040430 [debug] [ThreadPool]: SQL status: OK in 1.090 seconds
[0m14:40:35.047322 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db77-df71-1037-acf2-d56ff4dfbc6d, command-id=01f0db77-df8c-1132-b6dd-868a9d387179) - Closing
[0m14:40:35.047797 [debug] [ThreadPool]: On list_patreon_dev: Close
[0m14:40:35.048529 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-df71-1037-acf2-d56ff4dfbc6d) - Closing
[0m14:40:35.236791 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_patreon_dev_analytics_raw) - Creating connection
[0m14:40:35.237070 [debug] [ThreadPool]: Acquiring new databricks connection 'create_patreon_dev_analytics_raw'
[0m14:40:35.237309 [debug] [ThreadPool]: Creating schema "database: "patreon_dev"
schema: "analytics_raw"
"
[0m14:40:35.240746 [debug] [ThreadPool]: Using databricks connection "create_patreon_dev_analytics_raw"
[0m14:40:35.241122 [debug] [ThreadPool]: On create_patreon_dev_analytics_raw: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "create_patreon_dev_analytics_raw"} */
create schema if not exists `patreon_dev`.`analytics_raw`
  
[0m14:40:35.241329 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:35.852629 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e032-19d9-bfb1-af91d8558b13) - Created
[0m14:40:36.454136 [debug] [ThreadPool]: SQL status: OK in 1.210 seconds
[0m14:40:36.456387 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db77-e032-19d9-bfb1-af91d8558b13, command-id=01f0db77-e04c-19a4-9e40-db5292ff0ac6) - Closing
[0m14:40:36.457738 [debug] [ThreadPool]: On create_patreon_dev_analytics_raw: Close
[0m14:40:36.458429 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e032-19d9-bfb1-af91d8558b13) - Closing
[0m14:40:36.614288 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_marts) - Creating connection
[0m14:40:36.614696 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_staging) - Creating connection
[0m14:40:36.614911 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_marts'
[0m14:40:36.615317 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics) - Creating connection
[0m14:40:36.615722 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_raw) - Creating connection
[0m14:40:36.615923 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_staging'
[0m14:40:36.620365 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_marts"
[0m14:40:36.620604 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics'
[0m14:40:36.620864 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_raw'
[0m14:40:36.622561 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_staging"
[0m14:40:36.622887 [debug] [ThreadPool]: On list_patreon_dev_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_marts"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_marts'

  
[0m14:40:36.624547 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics"
[0m14:40:36.628643 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_raw"
[0m14:40:36.628979 [debug] [ThreadPool]: On list_patreon_dev_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_staging"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_staging'

  
[0m14:40:36.629335 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:36.629652 [debug] [ThreadPool]: On list_patreon_dev_analytics: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics'

  
[0m14:40:36.629970 [debug] [ThreadPool]: On list_patreon_dev_analytics_raw: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_raw'

  
[0m14:40:36.630243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:36.630598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:36.630899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:37.414927 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e123-169a-b05b-65d4e3605c3e) - Created
[0m14:40:37.415266 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e121-1828-b948-d14e14ca08d8) - Created
[0m14:40:37.424385 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e128-1863-88be-11525dc60083) - Created
[0m14:40:37.425079 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e128-13e8-bc6b-2d96f335b07c) - Created
[0m14:40:38.385888 [debug] [ThreadPool]: SQL status: OK in 1.760 seconds
[0m14:40:38.386265 [debug] [ThreadPool]: SQL status: OK in 1.760 seconds
[0m14:40:38.388358 [debug] [ThreadPool]: SQL status: OK in 1.760 seconds
[0m14:40:38.389258 [debug] [ThreadPool]: SQL status: OK in 1.760 seconds
[0m14:40:38.391041 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db77-e123-169a-b05b-65d4e3605c3e, command-id=01f0db77-e13b-1e16-ae0b-7da9af82e9ac) - Closing
[0m14:40:38.391921 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db77-e128-13e8-bc6b-2d96f335b07c, command-id=01f0db77-e13f-14dc-9ae5-71369322e1e2) - Closing
[0m14:40:38.392594 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db77-e121-1828-b948-d14e14ca08d8, command-id=01f0db77-e13b-163b-ba3d-cee84ef34c78) - Closing
[0m14:40:38.393286 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db77-e128-1863-88be-11525dc60083, command-id=01f0db77-e13f-1c25-8125-0074f8e48ac7) - Closing
[0m14:40:38.393554 [debug] [ThreadPool]: On list_patreon_dev_analytics_marts: Close
[0m14:40:38.393966 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e123-169a-b05b-65d4e3605c3e) - Closing
[0m14:40:38.557434 [debug] [ThreadPool]: On list_patreon_dev_analytics_raw: Close
[0m14:40:38.558821 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e128-13e8-bc6b-2d96f335b07c) - Closing
[0m14:40:38.731078 [debug] [ThreadPool]: On list_patreon_dev_analytics_staging: Close
[0m14:40:38.731517 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e121-1828-b948-d14e14ca08d8) - Closing
[0m14:40:38.888892 [debug] [ThreadPool]: On list_patreon_dev_analytics: Close
[0m14:40:38.889399 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db77-e128-1863-88be-11525dc60083) - Closing
[0m14:40:39.065134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d84f3b0>]}
[0m14:40:39.068573 [debug] [Thread-4 (]: Began running node seed.patreon_analytics.creators
[0m14:40:39.068898 [debug] [Thread-5 (]: Began running node seed.patreon_analytics.engagement_events
[0m14:40:39.069097 [debug] [Thread-6 (]: Began running node seed.patreon_analytics.patrons
[0m14:40:39.069404 [info ] [Thread-4 (]: 1 of 7 START seed file analytics_raw.creators .................................. [RUN]
[0m14:40:39.069698 [debug] [Thread-7 (]: Began running node seed.patreon_analytics.pledges
[0m14:40:39.070051 [info ] [Thread-5 (]: 2 of 7 START seed file analytics_raw.engagement_events ......................... [RUN]
[0m14:40:39.070422 [info ] [Thread-6 (]: 3 of 7 START seed file analytics_raw.patrons ................................... [RUN]
[0m14:40:39.070809 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.creators) - Creating connection
[0m14:40:39.071090 [info ] [Thread-7 (]: 4 of 7 START seed file analytics_raw.pledges ................................... [RUN]
[0m14:40:39.071365 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.engagement_events) - Creating connection
[0m14:40:39.071627 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.patrons) - Creating connection
[0m14:40:39.071965 [debug] [Thread-4 (]: Acquiring new databricks connection 'seed.patreon_analytics.creators'
[0m14:40:39.072364 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.pledges) - Creating connection
[0m14:40:39.072585 [debug] [Thread-5 (]: Acquiring new databricks connection 'seed.patreon_analytics.engagement_events'
[0m14:40:39.072817 [debug] [Thread-6 (]: Acquiring new databricks connection 'seed.patreon_analytics.patrons'
[0m14:40:39.073068 [debug] [Thread-4 (]: Began compiling node seed.patreon_analytics.creators
[0m14:40:39.073371 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.patreon_analytics.pledges'
[0m14:40:39.073581 [debug] [Thread-5 (]: Began compiling node seed.patreon_analytics.engagement_events
[0m14:40:39.073772 [debug] [Thread-6 (]: Began compiling node seed.patreon_analytics.patrons
[0m14:40:39.074014 [debug] [Thread-4 (]: Began executing node seed.patreon_analytics.creators
[0m14:40:39.074341 [debug] [Thread-7 (]: Began compiling node seed.patreon_analytics.pledges
[0m14:40:39.074641 [debug] [Thread-5 (]: Began executing node seed.patreon_analytics.engagement_events
[0m14:40:39.074891 [debug] [Thread-6 (]: Began executing node seed.patreon_analytics.patrons
[0m14:40:39.078402 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:40:39.078901 [debug] [Thread-7 (]: Began executing node seed.patreon_analytics.pledges
[0m14:40:39.080836 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:40:39.082616 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:40:39.083000 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d90aba0>]}
[0m14:40:39.084741 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:40:39.085131 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d96dd00>]}
[0m14:40:39.085421 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d988ec0>]}
[0m14:40:39.092116 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d9a8440>]}
[0m14:40:39.241673 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:40:39.242573 [debug] [Thread-7 (]: Using databricks connection "seed.patreon_analytics.pledges"
[0m14:40:39.243690 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.creators"
[0m14:40:39.246034 [debug] [Thread-6 (]: Using databricks connection "seed.patreon_analytics.patrons"
[0m14:40:39.246321 [debug] [Thread-5 (]: On seed.patreon_analytics.engagement_events: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.engagement_events"} */

    create  table `patreon_dev`.`analytics_raw`.`engagement_events` (event_id string ,patron_id string ,creator_id string ,post_id string ,event_type string ,event_at timestamp )
    
    using delta
  
    
    
    
    
    
  
[0m14:40:39.246923 [debug] [Thread-7 (]: On seed.patreon_analytics.pledges: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.pledges"} */

    create  table `patreon_dev`.`analytics_raw`.`pledges` (pledge_id string ,patron_id string ,creator_id string ,tier_id string ,pledge_amount_usd decimal(10,2) ,pledge_status string ,is_first_pledge boolean ,started_at timestamp ,ended_at timestamp ,pause_started_at timestamp ,churn_reason string )
    
    using delta
  
    
    
    
    
    
  
[0m14:40:39.247205 [debug] [Thread-4 (]: On seed.patreon_analytics.creators: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.creators"} */

    create  table `patreon_dev`.`analytics_raw`.`creators` (creator_id string ,creator_name string ,email string ,category string ,subcategory string ,country_code string ,currency_code string ,plan_type string ,is_nsfw boolean ,is_verified boolean ,created_at timestamp ,first_pledge_received_at timestamp ,last_post_at timestamp ,status string )
    
    using delta
  
    
    
    
    
    
  
[0m14:40:39.247430 [debug] [Thread-6 (]: On seed.patreon_analytics.patrons: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.patrons"} */

    create  table `patreon_dev`.`analytics_raw`.`patrons` (patron_id string ,patron_name string ,email string ,country_code string ,created_at timestamp ,first_pledge_at timestamp ,lifetime_spend_usd double ,status string )
    
    using delta
  
    
    
    
    
    
  
[0m14:40:39.247618 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:40:39.247780 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:40:39.247935 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:40:39.248086 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:40:40.003833 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db77-e2b1-1878-bbd7-77b3481189f3) - Created
[0m14:40:40.024381 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db77-e2b4-14b6-a4d4-6885a85ac28e) - Created
[0m14:40:40.053355 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db77-e2b9-1605-9494-9458ace7d006) - Created
[0m14:40:40.072666 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db77-e2b8-19ff-8198-022ac92b5b09) - Created
[0m14:40:42.942053 [debug] [Thread-6 (]: SQL status: OK in 3.690 seconds
[0m14:40:42.943402 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b4-14b6-a4d4-6885a85ac28e, command-id=01f0db77-e2c9-1ed5-8b61-dca34df251b3) - Closing
[0m14:40:42.973748 [debug] [Thread-5 (]: SQL status: OK in 3.730 seconds
[0m14:40:42.975130 [debug] [Thread-6 (]: Using databricks connection "seed.patreon_analytics.patrons"
[0m14:40:42.975963 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b8-19ff-8198-022ac92b5b09, command-id=01f0db77-e2d3-1f50-ab8d-b712bc1fff3c) - Closing
[0m14:40:42.976342 [debug] [Thread-6 (]: On seed.patreon_analytics.patrons: 
          insert overwrite `patreon_dev`.`analytics_raw`.`patrons` values
          (%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%...
[0m14:40:42.993636 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:40:42.995409 [debug] [Thread-4 (]: SQL status: OK in 3.750 seconds
[0m14:40:42.995833 [debug] [Thread-5 (]: On seed.patreon_analytics.engagement_events: 
          insert overwrite `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:40:42.996558 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b9-1605-9494-9458ace7d006, command-id=01f0db77-e2d0-1da4-bd99-d5d78e1d6a60) - Closing
[0m14:40:43.003758 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.creators"
[0m14:40:43.004104 [debug] [Thread-4 (]: On seed.patreon_analytics.creators: 
          insert overwrite `patreon_dev`.`analytics_raw`.`creators` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s...
[0m14:40:43.006956 [debug] [Thread-7 (]: SQL status: OK in 3.760 seconds
[0m14:40:43.007501 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b1-1878-bbd7-77b3481189f3, command-id=01f0db77-e2c6-1ced-9bb5-588f18b671ad) - Closing
[0m14:40:43.024628 [debug] [Thread-7 (]: Using databricks connection "seed.patreon_analytics.pledges"
[0m14:40:43.024998 [debug] [Thread-7 (]: On seed.patreon_analytics.pledges: 
          insert overwrite `patreon_dev`.`analytics_raw`.`pledges` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,...
[0m14:40:47.500296 [debug] [Thread-7 (]: SQL status: OK in 4.470 seconds
[0m14:40:47.500772 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b1-1878-bbd7-77b3481189f3, command-id=01f0db77-e493-1859-986d-826dca72bec9) - Closing
[0m14:40:47.504294 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.patreon_analytics.pledges"
[0m14:40:47.514215 [debug] [Thread-7 (]: On seed.patreon_analytics.pledges: Close
[0m14:40:47.514517 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db77-e2b1-1878-bbd7-77b3481189f3) - Closing
[0m14:40:47.528059 [debug] [Thread-4 (]: SQL status: OK in 4.520 seconds
[0m14:40:47.528390 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b9-1605-9494-9458ace7d006, command-id=01f0db77-e493-11d5-b801-7a174949fcd6) - Closing
[0m14:40:47.528805 [debug] [Thread-4 (]: Writing runtime SQL for node "seed.patreon_analytics.creators"
[0m14:40:47.675235 [debug] [Thread-4 (]: On seed.patreon_analytics.creators: Close
[0m14:40:47.677214 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db77-e2b9-1605-9494-9458ace7d006) - Closing
[0m14:40:47.867231 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d8dd850>]}
[0m14:40:47.867555 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d938bf0>]}
[0m14:40:47.868081 [info ] [Thread-7 (]: 4 of 7 OK loaded seed file analytics_raw.pledges ............................... [[32mINSERT 60[0m in 8.79s]
[0m14:40:47.868438 [info ] [Thread-4 (]: 1 of 7 OK loaded seed file analytics_raw.creators .............................. [[32mINSERT 15[0m in 8.80s]
[0m14:40:47.868900 [debug] [Thread-7 (]: Finished running node seed.patreon_analytics.pledges
[0m14:40:47.869239 [debug] [Thread-4 (]: Finished running node seed.patreon_analytics.creators
[0m14:40:47.869533 [debug] [Thread-7 (]: Began running node seed.patreon_analytics.posts
[0m14:40:47.869850 [debug] [Thread-4 (]: Began running node seed.patreon_analytics.tiers
[0m14:40:47.870198 [info ] [Thread-7 (]: 5 of 7 START seed file analytics_raw.posts ..................................... [RUN]
[0m14:40:47.870578 [info ] [Thread-4 (]: 6 of 7 START seed file analytics_raw.tiers ..................................... [RUN]
[0m14:40:47.870949 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.posts) - Creating connection
[0m14:40:47.871232 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.tiers) - Creating connection
[0m14:40:47.871438 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.patreon_analytics.posts'
[0m14:40:47.871704 [debug] [Thread-4 (]: Acquiring new databricks connection 'seed.patreon_analytics.tiers'
[0m14:40:47.872027 [debug] [Thread-7 (]: Began compiling node seed.patreon_analytics.posts
[0m14:40:47.872374 [debug] [Thread-4 (]: Began compiling node seed.patreon_analytics.tiers
[0m14:40:47.872662 [debug] [Thread-7 (]: Began executing node seed.patreon_analytics.posts
[0m14:40:47.873055 [debug] [Thread-4 (]: Began executing node seed.patreon_analytics.tiers
[0m14:40:47.880042 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.tiers"
[0m14:40:47.881072 [debug] [Thread-4 (]: On seed.patreon_analytics.tiers: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.tiers"} */

    create  table `patreon_dev`.`analytics_raw`.`tiers` (tier_id string ,creator_id string ,tier_name string ,tier_rank bigint ,price_usd decimal(10,2) ,description string ,is_active boolean ,created_at timestamp ,archived_at bigint )
    
    using delta
  
    
    
    
    
    
  
[0m14:40:47.882066 [debug] [Thread-7 (]: Using databricks connection "seed.patreon_analytics.posts"
[0m14:40:47.882295 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:40:47.882609 [debug] [Thread-7 (]: On seed.patreon_analytics.posts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.posts"} */

    create  table `patreon_dev`.`analytics_raw`.`posts` (post_id string ,creator_id string ,title string ,post_type string ,access_level string ,minimum_tier_id string ,published_at timestamp ,is_pinned boolean )
    
    using delta
  
    
    
    
    
    
  
[0m14:40:47.882965 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:40:48.580482 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db77-e7ce-1390-8133-42773aa0159c) - Created
[0m14:40:48.679982 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db77-e7cf-175d-8524-9aaf8dca39f7) - Created
[0m14:40:48.681934 [debug] [Thread-6 (]: SQL status: OK in 5.690 seconds
[0m14:40:48.682378 [debug] [Thread-5 (]: SQL status: OK in 5.690 seconds
[0m14:40:48.682615 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b4-14b6-a4d4-6885a85ac28e, command-id=01f0db77-e48f-12f3-aad8-3bb18cd52a3f) - Closing
[0m14:40:48.682964 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db77-e2b8-19ff-8198-022ac92b5b09, command-id=01f0db77-e492-102e-8123-ba378c065820) - Closing
[0m14:40:48.867934 [debug] [Thread-6 (]: Writing runtime SQL for node "seed.patreon_analytics.patrons"
[0m14:40:48.869464 [debug] [Thread-6 (]: On seed.patreon_analytics.patrons: Close
[0m14:40:48.869707 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db77-e2b4-14b6-a4d4-6885a85ac28e) - Closing
[0m14:40:48.899289 [debug] [Thread-5 (]: Writing runtime SQL for node "seed.patreon_analytics.engagement_events"
[0m14:40:49.024581 [debug] [Thread-5 (]: On seed.patreon_analytics.engagement_events: Close
[0m14:40:49.024943 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db77-e2b8-19ff-8198-022ac92b5b09) - Closing
[0m14:40:49.201663 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d925190>]}
[0m14:40:49.203968 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d96da30>]}
[0m14:40:49.204821 [info ] [Thread-6 (]: 3 of 7 OK loaded seed file analytics_raw.patrons ............................... [[32mINSERT 40[0m in 10.13s]
[0m14:40:49.205619 [info ] [Thread-5 (]: 2 of 7 OK loaded seed file analytics_raw.engagement_events ..................... [[32mINSERT 83[0m in 10.13s]
[0m14:40:49.206088 [debug] [Thread-6 (]: Finished running node seed.patreon_analytics.patrons
[0m14:40:49.206382 [debug] [Thread-5 (]: Finished running node seed.patreon_analytics.engagement_events
[0m14:40:49.206748 [debug] [Thread-6 (]: Began running node seed.patreon_analytics.transactions
[0m14:40:49.207240 [info ] [Thread-6 (]: 7 of 7 START seed file analytics_raw.transactions .............................. [RUN]
[0m14:40:49.207692 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.transactions) - Creating connection
[0m14:40:49.207924 [debug] [Thread-6 (]: Acquiring new databricks connection 'seed.patreon_analytics.transactions'
[0m14:40:49.208115 [debug] [Thread-6 (]: Began compiling node seed.patreon_analytics.transactions
[0m14:40:49.208296 [debug] [Thread-6 (]: Began executing node seed.patreon_analytics.transactions
[0m14:40:49.218056 [debug] [Thread-6 (]: Compilation Error in seed transactions (seeds/transactions.csv)
  Row 57 has 14 values, but Table only has 13 columns.
  
  > in macro create_seed_v1 (macros/materializations/seeds/seeds.sql)
  > called by macro materialization_seed_databricks (macros/materializations/seeds/seeds.sql)
  > called by seed transactions (seeds/transactions.csv)
[0m14:40:49.218608 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cf8ef00>]}
[0m14:40:49.218915 [error] [Thread-6 (]: 7 of 7 ERROR loading seed file analytics_raw.transactions ...................... [[31mERROR[0m in 0.01s]
[0m14:40:49.219194 [debug] [Thread-6 (]: Finished running node seed.patreon_analytics.transactions
[0m14:40:49.219439 [debug] [Thread-10 ]: Marking all children of 'seed.patreon_analytics.transactions' to be skipped because of status 'error'.  Reason: Compilation Error in seed transactions (seeds/transactions.csv)
  Row 57 has 14 values, but Table only has 13 columns.
  
  > in macro create_seed_v1 (macros/materializations/seeds/seeds.sql)
  > called by macro materialization_seed_databricks (macros/materializations/seeds/seeds.sql)
  > called by seed transactions (seeds/transactions.csv).
[0m14:40:50.497536 [debug] [Thread-4 (]: SQL status: OK in 2.620 seconds
[0m14:40:50.498297 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db77-e7ce-1390-8133-42773aa0159c, command-id=01f0db77-e7f2-1f3a-b098-cef7fe7c566c) - Closing
[0m14:40:50.511001 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.tiers"
[0m14:40:50.511410 [debug] [Thread-4 (]: On seed.patreon_analytics.tiers: 
          insert overwrite `patreon_dev`.`analytics_raw`.`tiers` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%...
[0m14:40:50.523101 [debug] [Thread-7 (]: SQL status: OK in 2.640 seconds
[0m14:40:50.523752 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0db77-e7cf-175d-8524-9aaf8dca39f7, command-id=01f0db77-e7f6-14b0-88ed-e16b0ce922e4) - Closing
[0m14:40:50.534147 [debug] [Thread-7 (]: Using databricks connection "seed.patreon_analytics.posts"
[0m14:40:50.534592 [debug] [Thread-7 (]: On seed.patreon_analytics.posts: 
          insert overwrite `patreon_dev`.`analytics_raw`.`posts` values
          (%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,...
[0m14:40:52.026261 [debug] [Thread-4 (]: SQL status: OK in 1.510 seconds
[0m14:40:52.026936 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db77-e7ce-1390-8133-42773aa0159c, command-id=01f0db77-e90c-181f-af72-28e02d75d043) - Closing
[0m14:40:52.027723 [debug] [Thread-4 (]: Writing runtime SQL for node "seed.patreon_analytics.tiers"
[0m14:40:52.030164 [debug] [Thread-4 (]: On seed.patreon_analytics.tiers: Close
[0m14:40:52.030603 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db77-e7ce-1390-8133-42773aa0159c) - Closing
[0m14:40:52.137898 [debug] [Thread-7 (]: SQL status: OK in 1.600 seconds
[0m14:40:52.138463 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0db77-e7cf-175d-8524-9aaf8dca39f7, command-id=01f0db77-e910-1166-8049-5b8270b31b7f) - Closing
[0m14:40:52.139078 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.patreon_analytics.posts"
[0m14:40:52.210735 [debug] [Thread-7 (]: On seed.patreon_analytics.posts: Close
[0m14:40:52.211157 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db77-e7cf-175d-8524-9aaf8dca39f7) - Closing
[0m14:40:52.373737 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd09c40>]}
[0m14:40:52.374133 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffb9479b-238a-4a4f-9e5d-51b4027e3978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd09190>]}
[0m14:40:52.374453 [info ] [Thread-4 (]: 6 of 7 OK loaded seed file analytics_raw.tiers ................................. [[32mINSERT 39[0m in 4.50s]
[0m14:40:52.374732 [info ] [Thread-7 (]: 5 of 7 OK loaded seed file analytics_raw.posts ................................. [[32mINSERT 46[0m in 4.50s]
[0m14:40:52.375006 [debug] [Thread-4 (]: Finished running node seed.patreon_analytics.tiers
[0m14:40:52.375242 [debug] [Thread-7 (]: Finished running node seed.patreon_analytics.posts
[0m14:40:52.376222 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:40:52.376489 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:40:52.376762 [info ] [MainThread]: 
[0m14:40:52.376955 [info ] [MainThread]: Finished running 7 seeds in 0 hours 0 minutes and 18.44 seconds (18.44s).
[0m14:40:52.377698 [debug] [MainThread]: Command end result
[0m14:40:52.407811 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:40:52.410797 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:40:52.414836 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/run_results.json
[0m14:40:52.415111 [info ] [MainThread]: 
[0m14:40:52.415382 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:40:52.415592 [info ] [MainThread]: 
[0m14:40:52.415850 [error] [MainThread]: [31mFailure in seed transactions (seeds/transactions.csv)[0m
[0m14:40:52.416089 [error] [MainThread]:   Compilation Error in seed transactions (seeds/transactions.csv)
  Row 57 has 14 values, but Table only has 13 columns.
  
  > in macro create_seed_v1 (macros/materializations/seeds/seeds.sql)
  > called by macro materialization_seed_databricks (macros/materializations/seeds/seeds.sql)
  > called by seed transactions (seeds/transactions.csv)
[0m14:40:52.416288 [info ] [MainThread]: 
[0m14:40:52.416497 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=7
[0m14:40:52.419741 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 20.0205, "process_in_blocks": "0", "process_kernel_time": 0.424739, "process_mem_max_rss": "284229632", "process_out_blocks": "0", "process_user_time": 5.164897}
[0m14:40:52.420096 [debug] [MainThread]: Command `dbt seed` failed at 14:40:52.420043 after 20.02 seconds
[0m14:40:52.420359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b350dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d84cd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d9d7fb0>]}
[0m14:40:52.420590 [debug] [MainThread]: Flushing usage events
[0m14:40:52.771933 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:44:40.578301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108952750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b36240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b35940>]}


============================== 14:44:40.581967 | bc497619-feca-4218-a5ba-7bcc820edfea ==============================
[0m14:44:40.581967 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:44:40.582430 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'quiet': 'False', 'printer_width': '80', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'empty': 'None', 'log_cache_events': 'False', 'target_path': 'None', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:44:40.677184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc497619-feca-4218-a5ba-7bcc820edfea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10833e900>]}
[0m14:44:40.732022 [debug] [MainThread]: Set downloads directory='/var/folders/17/44fmtn0931x0k_v05ghc5pl40000gn/T/dbt-downloads-725549vz'
[0m14:44:40.732329 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:44:41.164648 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:44:41.166036 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:44:41.305207 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:44:41.307739 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json
[0m14:44:41.558749 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json 200
[0m14:44:41.560762 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `calogica/dbt_expectations` package is deprecated in favor of
`metaplane/dbt_expectations`. Please update your `packages.yml` configuration to
use `metaplane/dbt_expectations` instead.
[0m14:44:41.561065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'bc497619-feca-4218-a5ba-7bcc820edfea', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b34e60>]}
[0m14:44:41.562802 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m14:44:41.810644 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m14:44:41.813039 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json
[0m14:44:42.046279 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json 200
[0m14:44:42.048578 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:44:42.631367 [info ] [MainThread]: Installed from version 1.3.3
[0m14:44:42.631649 [info ] [MainThread]: Up to date!
[0m14:44:42.631858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'bc497619-feca-4218-a5ba-7bcc820edfea', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dae960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10993ac30>]}
[0m14:44:42.632068 [info ] [MainThread]: Installing calogica/dbt_expectations
[0m14:44:43.668281 [info ] [MainThread]: Installed from version 0.10.4
[0m14:44:43.668594 [info ] [MainThread]: Up to date!
[0m14:44:43.668807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'bc497619-feca-4218-a5ba-7bcc820edfea', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c77290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c765a0>]}
[0m14:44:43.669034 [info ] [MainThread]: Installing dbt-labs/codegen
[0m14:44:44.101107 [info ] [MainThread]: Installed from version 0.14.0
[0m14:44:44.101392 [info ] [MainThread]: Up to date!
[0m14:44:44.101598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'bc497619-feca-4218-a5ba-7bcc820edfea', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c3d0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d39310>]}
[0m14:44:44.101811 [info ] [MainThread]: Installing calogica/dbt_date
[0m14:44:44.621455 [info ] [MainThread]: Installed from version 0.10.1
[0m14:44:44.621763 [info ] [MainThread]: Up to date!
[0m14:44:44.621990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'bc497619-feca-4218-a5ba-7bcc820edfea', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bd58b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bd54c0>]}
[0m14:44:44.623334 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageRedirectDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:44:44.625992 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 4.0912156, "process_in_blocks": "0", "process_kernel_time": 0.328034, "process_mem_max_rss": "149946368", "process_out_blocks": "0", "process_user_time": 1.691471}
[0m14:44:44.626411 [debug] [MainThread]: Command `dbt deps` succeeded at 14:44:44.626347 after 4.09 seconds
[0m14:44:44.626665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109be9dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ad2ff0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a5430>]}
[0m14:44:44.626910 [debug] [MainThread]: Flushing usage events
[0m14:44:45.124649 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:44:47.058857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12132e9f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c2b110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c2a990>]}


============================== 14:44:47.062022 | 6bea731b-ebd5-428c-9c26-42ad4d4de120 ==============================
[0m14:44:47.062022 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:44:47.062574 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'empty': 'None', 'indirect_selection': 'eager', 'warn_error': 'None', 'static_parser': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'use_colors': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'fail_fast': 'False', 'quiet': 'False', 'no_print': 'None', 'debug': 'False', 'invocation_command': 'dbt seed'}
[0m14:44:47.547889 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:44:47.548247 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:44:47.548417 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:44:48.175855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1214afec0>]}
[0m14:44:48.208080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x135e6f530>]}
[0m14:44:48.208526 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:44:48.298945 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:44:48.299537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136367d40>]}
[0m14:44:48.318898 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:44:48.449278 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 7 files changed.
[0m14:44:48.449796 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/tiers.csv
[0m14:44:48.450022 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/pledges.csv
[0m14:44:48.450219 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/creators.csv
[0m14:44:48.450398 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/posts.csv
[0m14:44:48.450577 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/transactions.csv
[0m14:44:48.450751 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/patrons.csv
[0m14:44:48.450920 [debug] [MainThread]: Partial parsing: updated file: patreon_analytics://seeds/engagement_events.csv
[0m14:44:48.595372 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.patreon_analytics.intermediate
- models.patreon_analytics.marts.finance
[0m14:44:48.599053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136dfdac0>]}
[0m14:44:48.671979 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:44:48.674137 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:44:48.764177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136e6d790>]}
[0m14:44:48.764490 [info ] [MainThread]: Found 9 models, 36 data tests, 7 seeds, 4 metrics, 1126 macros, 1 semantic model
[0m14:44:48.764675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e67890>]}
[0m14:44:48.766098 [info ] [MainThread]: 
[0m14:44:48.766336 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:44:48.766489 [info ] [MainThread]: 
[0m14:44:48.766801 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:44:48.766963 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:44:48.770376 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev) - Creating connection
[0m14:44:48.770684 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev'
[0m14:44:48.777122 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev"
[0m14:44:48.777366 [debug] [ThreadPool]: On list_patreon_dev: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
[0m14:44:48.777529 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:49.463428 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7760-1d28-b0ea-070087fbcbdc) - Created
[0m14:44:49.891474 [debug] [ThreadPool]: SQL status: OK in 1.110 seconds
[0m14:44:49.900195 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-7760-1d28-b0ea-070087fbcbdc, command-id=01f0db78-777a-1a7b-a803-8eac2a72ddc2) - Closing
[0m14:44:49.901080 [debug] [ThreadPool]: On list_patreon_dev: Close
[0m14:44:49.901490 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7760-1d28-b0ea-070087fbcbdc) - Closing
[0m14:44:50.082236 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_marts) - Creating connection
[0m14:44:50.082702 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics) - Creating connection
[0m14:44:50.082897 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_marts'
[0m14:44:50.083162 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_staging) - Creating connection
[0m14:44:50.083490 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_raw) - Creating connection
[0m14:44:50.083695 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics'
[0m14:44:50.087761 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_marts"
[0m14:44:50.088074 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_staging'
[0m14:44:50.088313 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_raw'
[0m14:44:50.090292 [debug] [ThreadPool]: On list_patreon_dev_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_marts"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_marts'

  
[0m14:44:50.093127 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics"
[0m14:44:50.095465 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_staging"
[0m14:44:50.097620 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_raw"
[0m14:44:50.097851 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:50.098086 [debug] [ThreadPool]: On list_patreon_dev_analytics: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics'

  
[0m14:44:50.098334 [debug] [ThreadPool]: On list_patreon_dev_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_staging"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_staging'

  
[0m14:44:50.098573 [debug] [ThreadPool]: On list_patreon_dev_analytics_raw: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_raw'

  
[0m14:44:50.098852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:50.099246 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:50.099506 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:50.973551 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7847-14c6-8c01-819f3b6c59dd) - Created
[0m14:44:50.977898 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7842-1674-b558-32925d842519) - Created
[0m14:44:51.052009 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7853-1e3d-9d6e-a1e94f0b8f7e) - Created
[0m14:44:51.057761 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7853-16a9-a238-412ffa9aa048) - Created
[0m14:44:51.458210 [debug] [ThreadPool]: SQL status: OK in 1.360 seconds
[0m14:44:51.459006 [debug] [ThreadPool]: SQL status: OK in 1.360 seconds
[0m14:44:51.460794 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-7853-16a9-a238-412ffa9aa048, command-id=01f0db78-786a-12fd-93b5-8daee8e2ce2c) - Closing
[0m14:44:51.461169 [debug] [ThreadPool]: On list_patreon_dev_analytics_marts: Close
[0m14:44:51.461411 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7853-16a9-a238-412ffa9aa048) - Closing
[0m14:44:51.462436 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-7842-1674-b558-32925d842519, command-id=01f0db78-785d-14a7-bd27-9281511d82d0) - Closing
[0m14:44:51.484270 [debug] [ThreadPool]: SQL status: OK in 1.390 seconds
[0m14:44:51.485638 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-7853-1e3d-9d6e-a1e94f0b8f7e, command-id=01f0db78-786b-1958-a04c-3f8fcbb66976) - Closing
[0m14:44:51.634297 [debug] [ThreadPool]: SQL status: OK in 1.530 seconds
[0m14:44:51.635852 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-7847-14c6-8c01-819f3b6c59dd, command-id=01f0db78-785d-11cb-84bc-202100e51196) - Closing
[0m14:44:51.640021 [debug] [ThreadPool]: On list_patreon_dev_analytics_staging: Close
[0m14:44:51.640344 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7842-1674-b558-32925d842519) - Closing
[0m14:44:51.801756 [debug] [ThreadPool]: On list_patreon_dev_analytics: Close
[0m14:44:51.802547 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7853-1e3d-9d6e-a1e94f0b8f7e) - Closing
[0m14:44:51.968579 [debug] [ThreadPool]: On list_patreon_dev_analytics_raw: Close
[0m14:44:51.969363 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-7847-14c6-8c01-819f3b6c59dd) - Closing
[0m14:44:52.137504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122015f10>]}
[0m14:44:52.141160 [debug] [Thread-3 (]: Began running node seed.patreon_analytics.creators
[0m14:44:52.141495 [debug] [Thread-4 (]: Began running node seed.patreon_analytics.engagement_events
[0m14:44:52.141725 [debug] [Thread-5 (]: Began running node seed.patreon_analytics.patrons
[0m14:44:52.142044 [info ] [Thread-3 (]: 1 of 7 START seed file analytics_raw.creators .................................. [RUN]
[0m14:44:52.142323 [debug] [Thread-6 (]: Began running node seed.patreon_analytics.pledges
[0m14:44:52.142648 [info ] [Thread-4 (]: 2 of 7 START seed file analytics_raw.engagement_events ......................... [RUN]
[0m14:44:52.142979 [info ] [Thread-5 (]: 3 of 7 START seed file analytics_raw.patrons ................................... [RUN]
[0m14:44:52.143398 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.creators) - Creating connection
[0m14:44:52.143900 [info ] [Thread-6 (]: 4 of 7 START seed file analytics_raw.pledges ................................... [RUN]
[0m14:44:52.144488 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.engagement_events) - Creating connection
[0m14:44:52.145002 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.patrons) - Creating connection
[0m14:44:52.145387 [debug] [Thread-3 (]: Acquiring new databricks connection 'seed.patreon_analytics.creators'
[0m14:44:52.145796 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.pledges) - Creating connection
[0m14:44:52.146115 [debug] [Thread-4 (]: Acquiring new databricks connection 'seed.patreon_analytics.engagement_events'
[0m14:44:52.146370 [debug] [Thread-5 (]: Acquiring new databricks connection 'seed.patreon_analytics.patrons'
[0m14:44:52.147003 [debug] [Thread-6 (]: Acquiring new databricks connection 'seed.patreon_analytics.pledges'
[0m14:44:52.147911 [debug] [Thread-4 (]: Began compiling node seed.patreon_analytics.engagement_events
[0m14:44:52.148963 [debug] [Thread-5 (]: Began compiling node seed.patreon_analytics.patrons
[0m14:44:52.146628 [debug] [Thread-3 (]: Began compiling node seed.patreon_analytics.creators
[0m14:44:52.151899 [debug] [Thread-6 (]: Began compiling node seed.patreon_analytics.pledges
[0m14:44:52.152260 [debug] [Thread-4 (]: Began executing node seed.patreon_analytics.engagement_events
[0m14:44:52.152538 [debug] [Thread-5 (]: Began executing node seed.patreon_analytics.patrons
[0m14:44:52.152774 [debug] [Thread-3 (]: Began executing node seed.patreon_analytics.creators
[0m14:44:52.152998 [debug] [Thread-6 (]: Began executing node seed.patreon_analytics.pledges
[0m14:44:52.156440 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:44:52.158921 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:44:52.161587 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:44:52.163244 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136e7c200>]}
[0m14:44:52.166773 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136e93530>]}
[0m14:44:52.166502 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:44:52.167173 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x136ed16a0>]}
[0m14:44:52.177354 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1364605f0>]}
[0m14:44:52.257618 [debug] [Thread-3 (]: Using databricks connection "seed.patreon_analytics.creators"
[0m14:44:52.281668 [debug] [Thread-3 (]: On seed.patreon_analytics.creators: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.creators"} */

    create or replace table `patreon_dev`.`analytics_raw`.`creators` (creator_id string ,creator_name string ,email string ,category string ,subcategory string ,country_code string ,currency_code string ,plan_type string ,is_nsfw boolean ,is_verified boolean ,created_at timestamp ,first_pledge_received_at timestamp ,last_post_at timestamp ,status string )
    
    using delta
  
    
    
    
    
    
  
[0m14:44:52.312110 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:44:52.557522 [debug] [Thread-6 (]: Using databricks connection "seed.patreon_analytics.pledges"
[0m14:44:52.558318 [debug] [Thread-6 (]: On seed.patreon_analytics.pledges: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.pledges"} */

    create or replace table `patreon_dev`.`analytics_raw`.`pledges` (pledge_id string ,patron_id string ,creator_id string ,tier_id string ,pledge_amount_usd decimal(10,2) ,pledge_status string ,is_first_pledge boolean ,started_at timestamp ,ended_at timestamp ,pause_started_at bigint ,churn_reason string )
    
    using delta
  
    
    
    
    
    
  
[0m14:44:52.558762 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:44:52.806972 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.patrons"
[0m14:44:52.813440 [debug] [Thread-5 (]: On seed.patreon_analytics.patrons: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.patrons"} */

    create or replace table `patreon_dev`.`analytics_raw`.`patrons` (patron_id string ,patron_name string ,email string ,country_code string ,created_at timestamp ,first_pledge_at timestamp ,lifetime_spend_usd double ,status string )
    
    using delta
  
    
    
    
    
    
  
[0m14:44:52.813852 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:44:53.247256 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f0db78-7997-144b-9f99-109e0337913c) - Created
[0m14:44:53.252657 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:44:53.253356 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.engagement_events"} */

    create or replace table `patreon_dev`.`analytics_raw`.`engagement_events` (event_id string ,patron_id string ,creator_id string ,post_id string ,event_type string ,event_at timestamp )
    
    using delta
  
    
    
    
    
    
  
[0m14:44:53.253601 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:44:53.344678 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-79ac-1581-a6fd-a619c0627225) - Created
[0m14:44:53.514550 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-79c8-1fb6-9814-621db08ed72b) - Created
[0m14:44:54.042721 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301) - Created
[0m14:44:54.844390 [debug] [Thread-5 (]: SQL status: OK in 2.030 seconds
[0m14:44:54.845186 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-79c8-1fb6-9814-621db08ed72b, command-id=01f0db78-79e1-10c0-ac8d-ad3d5ffb7b23) - Closing
[0m14:44:54.961653 [debug] [Thread-6 (]: SQL status: OK in 2.400 seconds
[0m14:44:54.968591 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-79ac-1581-a6fd-a619c0627225, command-id=01f0db78-79c8-1d59-a491-beb93cfef2c8) - Closing
[0m14:44:55.104215 [debug] [Thread-3 (]: SQL status: OK in 2.790 seconds
[0m14:44:55.117509 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f0db78-7997-144b-9f99-109e0337913c, command-id=01f0db78-79ba-1f4c-997f-62fa063c512b) - Closing
[0m14:44:55.389107 [debug] [Thread-4 (]: SQL status: OK in 2.140 seconds
[0m14:44:55.413973 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-7a33-1f57-9bb7-593eb6e87671) - Closing
[0m14:44:55.723761 [debug] [Thread-3 (]: Using databricks connection "seed.patreon_analytics.creators"
[0m14:44:55.730758 [debug] [Thread-3 (]: On seed.patreon_analytics.creators: 
          insert overwrite `patreon_dev`.`analytics_raw`.`creators` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s...
[0m14:44:57.752841 [debug] [Thread-3 (]: SQL status: OK in 2.020 seconds
[0m14:44:57.765638 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f0db78-7997-144b-9f99-109e0337913c, command-id=01f0db78-7b5e-1b0f-ad0e-ab96eae38d80) - Closing
[0m14:44:57.792887 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.patreon_analytics.creators"
[0m14:44:57.903726 [debug] [Thread-3 (]: On seed.patreon_analytics.creators: Close
[0m14:44:57.945828 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f0db78-7997-144b-9f99-109e0337913c) - Closing
[0m14:44:58.310263 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1214af170>]}
[0m14:44:58.328573 [info ] [Thread-3 (]: 1 of 7 OK loaded seed file analytics_raw.creators .............................. [[32mINSERT 500[0m in 6.00s]
[0m14:44:58.352508 [debug] [Thread-3 (]: Finished running node seed.patreon_analytics.creators
[0m14:44:58.359195 [debug] [Thread-3 (]: Began running node seed.patreon_analytics.posts
[0m14:44:58.378168 [info ] [Thread-3 (]: 5 of 7 START seed file analytics_raw.posts ..................................... [RUN]
[0m14:44:58.384977 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.posts) - Creating connection
[0m14:44:58.402809 [debug] [Thread-3 (]: Acquiring new databricks connection 'seed.patreon_analytics.posts'
[0m14:44:58.414909 [debug] [Thread-3 (]: Began compiling node seed.patreon_analytics.posts
[0m14:44:58.434081 [debug] [Thread-3 (]: Began executing node seed.patreon_analytics.posts
[0m14:44:58.869547 [debug] [Thread-3 (]: Using databricks connection "seed.patreon_analytics.posts"
[0m14:44:58.888285 [debug] [Thread-3 (]: On seed.patreon_analytics.posts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.posts"} */

    create or replace table `patreon_dev`.`analytics_raw`.`posts` (post_id string ,creator_id string ,title string ,post_type string ,access_level string ,minimum_tier_id string ,published_at timestamp ,is_pinned boolean )
    
    using delta
  
    
    
    
    
    
  
[0m14:44:58.906388 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:44:59.989617 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f0db78-7d9f-10c9-ab9b-28bacda79fd8) - Created
[0m14:45:00.034838 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:00.043260 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert overwrite `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:45:00.567343 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.patrons"
[0m14:45:00.577817 [debug] [Thread-5 (]: On seed.patreon_analytics.patrons: 
          insert overwrite `patreon_dev`.`analytics_raw`.`patrons` values
          (%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%...
[0m14:45:01.416805 [debug] [Thread-3 (]: SQL status: OK in 2.510 seconds
[0m14:45:01.423771 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f0db78-7d9f-10c9-ab9b-28bacda79fd8, command-id=01f0db78-7dc4-1c06-83fb-e4ea30709d4c) - Closing
[0m14:45:01.550676 [debug] [Thread-6 (]: Using databricks connection "seed.patreon_analytics.pledges"
[0m14:45:01.562525 [debug] [Thread-6 (]: On seed.patreon_analytics.pledges: 
          insert overwrite `patreon_dev`.`analytics_raw`.`pledges` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,...
[0m14:45:03.293432 [debug] [Thread-3 (]: Using databricks connection "seed.patreon_analytics.posts"
[0m14:45:03.297221 [debug] [Thread-3 (]: On seed.patreon_analytics.posts: 
          insert overwrite `patreon_dev`.`analytics_raw`.`posts` values
          (%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,...
[0m14:45:03.479079 [debug] [Thread-4 (]: SQL status: OK in 3.420 seconds
[0m14:45:03.479431 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-7e4c-1984-8e6d-d450e4b18199) - Closing
[0m14:45:04.262067 [debug] [Thread-5 (]: SQL status: OK in 3.670 seconds
[0m14:45:04.268240 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-79c8-1fb6-9814-621db08ed72b, command-id=01f0db78-7e9e-1f5f-8d02-b5770f4b5055) - Closing
[0m14:45:05.210610 [debug] [Thread-6 (]: SQL status: OK in 3.640 seconds
[0m14:45:05.229216 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-79ac-1581-a6fd-a619c0627225, command-id=01f0db78-7f44-18b1-8805-c50a6835c936) - Closing
[0m14:45:06.206976 [debug] [Thread-3 (]: SQL status: OK in 2.910 seconds
[0m14:45:06.226300 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f0db78-7d9f-10c9-ab9b-28bacda79fd8, command-id=01f0db78-8025-10dd-9f32-8d3431132bff) - Closing
[0m14:45:06.233377 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.patreon_analytics.posts"
[0m14:45:06.341947 [debug] [Thread-3 (]: On seed.patreon_analytics.posts: Close
[0m14:45:06.374714 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f0db78-7d9f-10c9-ab9b-28bacda79fd8) - Closing
[0m14:45:06.645693 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x162435cd0>]}
[0m14:45:06.651401 [info ] [Thread-3 (]: 5 of 7 OK loaded seed file analytics_raw.posts ................................. [[32mINSERT 8000[0m in 8.26s]
[0m14:45:06.715721 [debug] [Thread-3 (]: Finished running node seed.patreon_analytics.posts
[0m14:45:06.734382 [debug] [Thread-3 (]: Began running node seed.patreon_analytics.tiers
[0m14:45:06.747548 [info ] [Thread-3 (]: 6 of 7 START seed file analytics_raw.tiers ..................................... [RUN]
[0m14:45:06.790301 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.tiers) - Creating connection
[0m14:45:06.827185 [debug] [Thread-3 (]: Acquiring new databricks connection 'seed.patreon_analytics.tiers'
[0m14:45:06.827585 [debug] [Thread-3 (]: Began compiling node seed.patreon_analytics.tiers
[0m14:45:06.840579 [debug] [Thread-3 (]: Began executing node seed.patreon_analytics.tiers
[0m14:45:07.003593 [debug] [Thread-3 (]: Using databricks connection "seed.patreon_analytics.tiers"
[0m14:45:07.004021 [debug] [Thread-3 (]: On seed.patreon_analytics.tiers: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.tiers"} */

    create or replace table `patreon_dev`.`analytics_raw`.`tiers` (tier_id string ,creator_id string ,tier_name string ,tier_rank bigint ,price_usd decimal(10,2) ,description string ,is_active boolean ,created_at timestamp ,archived_at bigint )
    
    using delta
  
    
    
    
    
    
  
[0m14:45:07.004243 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:45:07.224556 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:07.238953 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert into `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%...
[0m14:45:07.407071 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.patrons"
[0m14:45:07.410260 [debug] [Thread-5 (]: On seed.patreon_analytics.patrons: 
          insert into `patreon_dev`.`analytics_raw`.`patrons` values
          (%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,...
[0m14:45:07.964513 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f0db78-8264-1659-be13-14559547b10a) - Created
[0m14:45:09.390046 [debug] [Thread-3 (]: SQL status: OK in 2.390 seconds
[0m14:45:09.397331 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f0db78-8264-1659-be13-14559547b10a, command-id=01f0db78-827f-1f89-b3f5-9365ffdefb1e) - Closing
[0m14:45:09.625634 [debug] [Thread-5 (]: SQL status: OK in 2.210 seconds
[0m14:45:09.631177 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-79c8-1fb6-9814-621db08ed72b, command-id=01f0db78-823a-16b1-8ff4-3a1a0dc96c7a) - Closing
[0m14:45:09.645023 [debug] [Thread-5 (]: Writing runtime SQL for node "seed.patreon_analytics.patrons"
[0m14:45:09.645750 [debug] [Thread-4 (]: SQL status: OK in 2.410 seconds
[0m14:45:09.671107 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-8243-13f2-9529-c72e9c3c1398) - Closing
[0m14:45:09.719984 [debug] [Thread-5 (]: On seed.patreon_analytics.patrons: Close
[0m14:45:09.726619 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-79c8-1fb6-9814-621db08ed72b) - Closing
[0m14:45:09.938941 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1444bbd40>]}
[0m14:45:09.945674 [info ] [Thread-5 (]: 3 of 7 OK loaded seed file analytics_raw.patrons ............................... [[32mINSERT 15000[0m in 17.79s]
[0m14:45:09.957153 [debug] [Thread-5 (]: Finished running node seed.patreon_analytics.patrons
[0m14:45:09.976379 [debug] [Thread-5 (]: Began running node seed.patreon_analytics.transactions
[0m14:45:09.982696 [info ] [Thread-5 (]: 7 of 7 START seed file analytics_raw.transactions .............................. [RUN]
[0m14:45:10.007440 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.patreon_analytics.transactions) - Creating connection
[0m14:45:10.014093 [debug] [Thread-5 (]: Acquiring new databricks connection 'seed.patreon_analytics.transactions'
[0m14:45:10.020316 [debug] [Thread-5 (]: Began compiling node seed.patreon_analytics.transactions
[0m14:45:10.026242 [debug] [Thread-5 (]: Began executing node seed.patreon_analytics.transactions
[0m14:45:10.409373 [debug] [Thread-3 (]: Using databricks connection "seed.patreon_analytics.tiers"
[0m14:45:10.422072 [debug] [Thread-3 (]: On seed.patreon_analytics.tiers: 
          insert overwrite `patreon_dev`.`analytics_raw`.`tiers` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%...
[0m14:45:12.599771 [debug] [Thread-3 (]: SQL status: OK in 2.130 seconds
[0m14:45:12.612822 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f0db78-8264-1659-be13-14559547b10a, command-id=01f0db78-8446-153b-933e-6465f6d8809d) - Closing
[0m14:45:12.631988 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.patreon_analytics.tiers"
[0m14:45:12.746211 [debug] [Thread-6 (]: Using databricks connection "seed.patreon_analytics.pledges"
[0m14:45:12.757452 [debug] [Thread-6 (]: On seed.patreon_analytics.pledges: 
          insert into `patreon_dev`.`analytics_raw`.`pledges` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s...
[0m14:45:12.758642 [debug] [Thread-3 (]: On seed.patreon_analytics.tiers: Close
[0m14:45:12.800622 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f0db78-8264-1659-be13-14559547b10a) - Closing
[0m14:45:13.097281 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:13.097669 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x17bb686e0>]}
[0m14:45:13.109372 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "seed.patreon_analytics.transactions"} */

    create  table `patreon_dev`.`analytics_raw`.`transactions` (transaction_id string ,pledge_id string ,patron_id string ,creator_id string ,transaction_type string ,transaction_status string ,gross_amount_usd decimal(10,2) ,platform_fee_usd decimal(10,2) ,processing_fee_usd decimal(10,2) ,net_amount_usd decimal(10,2) ,payment_method string ,failure_reason string ,transaction_at timestamp )
    
    using delta
  
    
    
    
    
    
  
[0m14:45:13.128363 [info ] [Thread-3 (]: 6 of 7 OK loaded seed file analytics_raw.tiers ................................. [[32mINSERT 1412[0m in 6.31s]
[0m14:45:13.147097 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:45:13.166132 [debug] [Thread-3 (]: Finished running node seed.patreon_analytics.tiers
[0m14:45:13.761333 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:13.764585 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert into `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%...
[0m14:45:13.861491 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922) - Created
[0m14:45:15.292396 [debug] [Thread-6 (]: SQL status: OK in 2.520 seconds
[0m14:45:15.292812 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-79ac-1581-a6fd-a619c0627225, command-id=01f0db78-8587-1ec3-be01-0c8ad8b64b37) - Closing
[0m14:45:15.742124 [debug] [Thread-6 (]: Using databricks connection "seed.patreon_analytics.pledges"
[0m14:45:15.743143 [debug] [Thread-6 (]: On seed.patreon_analytics.pledges: 
          insert into `patreon_dev`.`analytics_raw`.`pledges` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s...
[0m14:45:15.750840 [debug] [Thread-4 (]: SQL status: OK in 1.990 seconds
[0m14:45:15.751302 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-8602-1455-b391-b5e20c193b88) - Closing
[0m14:45:15.911428 [debug] [Thread-5 (]: SQL status: OK in 2.760 seconds
[0m14:45:15.918592 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-8601-1421-9bbe-820e45d832c6) - Closing
[0m14:45:16.989768 [debug] [Thread-6 (]: SQL status: OK in 1.250 seconds
[0m14:45:17.001144 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-79ac-1581-a6fd-a619c0627225, command-id=01f0db78-8724-15cf-acd8-3e8098fa284b) - Closing
[0m14:45:17.008601 [debug] [Thread-6 (]: Writing runtime SQL for node "seed.patreon_analytics.pledges"
[0m14:45:17.060394 [debug] [Thread-6 (]: On seed.patreon_analytics.pledges: Close
[0m14:45:17.071348 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-79ac-1581-a6fd-a619c0627225) - Closing
[0m14:45:17.276959 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x161b025d0>]}
[0m14:45:17.304628 [info ] [Thread-6 (]: 4 of 7 OK loaded seed file analytics_raw.pledges ............................... [[32mINSERT 21310[0m in 25.13s]
[0m14:45:17.317990 [debug] [Thread-6 (]: Finished running node seed.patreon_analytics.pledges
[0m14:45:19.200655 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:19.210333 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert into `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%...
[0m14:45:21.230937 [debug] [Thread-4 (]: SQL status: OK in 2.010 seconds
[0m14:45:21.236596 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:21.236899 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-894d-1a6e-b3bb-33b2cbc309f9) - Closing
[0m14:45:21.242878 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert overwrite `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s...
[0m14:45:22.940589 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:22.944030 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert into `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%...
[0m14:45:25.008236 [debug] [Thread-5 (]: SQL status: OK in 3.750 seconds
[0m14:45:25.009184 [debug] [Thread-4 (]: SQL status: OK in 2.060 seconds
[0m14:45:25.009548 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-8af6-1690-98d2-4a6195ef3f8d) - Closing
[0m14:45:25.009808 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-8b79-11e9-b2fb-5075adfd8cf5) - Closing
[0m14:45:28.133596 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:28.143264 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert into `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%...
[0m14:45:29.922410 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:29.928482 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:45:30.271143 [debug] [Thread-4 (]: SQL status: OK in 2.120 seconds
[0m14:45:30.271574 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-8ea0-12dd-affa-c2823380d257) - Closing
[0m14:45:30.319740 [debug] [Thread-4 (]: Using databricks connection "seed.patreon_analytics.engagement_events"
[0m14:45:30.320181 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: 
          insert into `patreon_dev`.`analytics_raw`.`engagement_events` values
          (%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s),(%...
[0m14:45:32.750213 [debug] [Thread-5 (]: SQL status: OK in 2.820 seconds
[0m14:45:32.750778 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-8faf-1628-a412-09a14ff0f87a) - Closing
[0m14:45:33.513084 [debug] [Thread-4 (]: SQL status: OK in 3.190 seconds
[0m14:45:33.519845 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301, command-id=01f0db78-8fd3-1959-afca-27f2ed77fa8e) - Closing
[0m14:45:33.527029 [debug] [Thread-4 (]: Writing runtime SQL for node "seed.patreon_analytics.engagement_events"
[0m14:45:33.577521 [debug] [Thread-4 (]: On seed.patreon_analytics.engagement_events: Close
[0m14:45:33.584159 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db78-7a0a-1f60-84b5-7db38ce56301) - Closing
[0m14:45:33.790662 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1369b66f0>]}
[0m14:45:33.796620 [info ] [Thread-4 (]: 2 of 7 OK loaded seed file analytics_raw.engagement_events ..................... [[32mINSERT 60226[0m in 41.65s]
[0m14:45:33.802331 [debug] [Thread-4 (]: Finished running node seed.patreon_analytics.engagement_events
[0m14:45:36.370934 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:36.377092 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:45:38.848487 [debug] [Thread-5 (]: SQL status: OK in 2.470 seconds
[0m14:45:38.850527 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-937d-1b93-ba46-a5776f0208cd) - Closing
[0m14:45:42.293323 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:42.299521 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:45:44.875136 [debug] [Thread-5 (]: SQL status: OK in 2.580 seconds
[0m14:45:44.875858 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-9703-1f40-9542-81bc160ee14d) - Closing
[0m14:45:48.050213 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:48.056298 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:45:50.916804 [debug] [Thread-5 (]: SQL status: OK in 2.860 seconds
[0m14:45:50.918172 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-9a76-13a7-b487-c43cb9678c76) - Closing
[0m14:45:54.250616 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:45:54.256816 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:45:56.748624 [debug] [Thread-5 (]: SQL status: OK in 2.490 seconds
[0m14:45:56.749014 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-9e22-1acf-8b6f-488e694702e5) - Closing
[0m14:46:00.074457 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:00.081173 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:04.375268 [debug] [Thread-5 (]: SQL status: OK in 4.290 seconds
[0m14:46:04.376298 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-a19b-1040-bda1-a1b07e83cfe7) - Closing
[0m14:46:07.699295 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:07.705684 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:10.635007 [debug] [Thread-5 (]: SQL status: OK in 2.930 seconds
[0m14:46:10.635367 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-a62b-1234-ba26-b7dc2a530629) - Closing
[0m14:46:14.156261 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:14.162944 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:17.635605 [debug] [Thread-5 (]: SQL status: OK in 3.470 seconds
[0m14:46:17.635986 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-aa00-12c2-8590-61154f69ae14) - Closing
[0m14:46:21.252351 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:21.259281 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:25.115012 [debug] [Thread-5 (]: SQL status: OK in 3.860 seconds
[0m14:46:25.115345 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-ae3a-1981-8266-296a33492a05) - Closing
[0m14:46:28.767767 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:28.774544 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:32.543906 [debug] [Thread-5 (]: SQL status: OK in 3.770 seconds
[0m14:46:32.544466 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-b2b4-1ed3-a50b-22c2b8cb3e03) - Closing
[0m14:46:35.958782 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:35.966040 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:39.127033 [debug] [Thread-5 (]: SQL status: OK in 3.160 seconds
[0m14:46:39.127909 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-b6fe-17f5-bf79-2047cd3481bf) - Closing
[0m14:46:42.571060 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:42.577514 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:45.398737 [debug] [Thread-5 (]: SQL status: OK in 2.820 seconds
[0m14:46:45.400648 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-baee-14eb-8ebd-715580ea0f3d) - Closing
[0m14:46:48.723787 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:48.729993 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:51.518207 [debug] [Thread-5 (]: SQL status: OK in 2.790 seconds
[0m14:46:51.519133 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-bea4-134f-b79b-7a28b5182436) - Closing
[0m14:46:54.786780 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:46:54.793919 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:46:57.719964 [debug] [Thread-5 (]: SQL status: OK in 2.930 seconds
[0m14:46:57.721146 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-c241-1872-9ad4-d471fc23f98a) - Closing
[0m14:47:01.181370 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:47:01.187621 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:47:04.137783 [debug] [Thread-5 (]: SQL status: OK in 2.950 seconds
[0m14:47:04.138139 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-c612-1b7a-8a75-a4b351c91b4c) - Closing
[0m14:47:08.092987 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:47:08.099475 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:47:11.775037 [debug] [Thread-5 (]: SQL status: OK in 3.680 seconds
[0m14:47:11.775448 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-ca30-1089-bcfc-e321d0f44d40) - Closing
[0m14:47:15.218258 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:47:15.224899 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:47:19.068758 [debug] [Thread-5 (]: SQL status: OK in 3.840 seconds
[0m14:47:19.069788 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-ce6e-1e16-bfa8-b974cb7a90a7) - Closing
[0m14:47:20.891001 [debug] [Thread-5 (]: Using databricks connection "seed.patreon_analytics.transactions"
[0m14:47:20.894416 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: 
          insert into `patreon_dev`.`analytics_raw`.`transactions` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%...
[0m14:47:23.819543 [debug] [Thread-5 (]: SQL status: OK in 2.920 seconds
[0m14:47:23.820791 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922, command-id=01f0db78-d1c4-15c8-a086-c6745996f948) - Closing
[0m14:47:23.822626 [debug] [Thread-5 (]: Writing runtime SQL for node "seed.patreon_analytics.transactions"
[0m14:47:23.827113 [debug] [Thread-5 (]: On seed.patreon_analytics.transactions: Close
[0m14:47:23.827439 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-85eb-188e-b2f0-38e1166f0922) - Closing
[0m14:47:24.005012 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bea731b-ebd5-428c-9c26-42ad4d4de120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x17aa815e0>]}
[0m14:47:24.005492 [info ] [Thread-5 (]: 7 of 7 OK loaded seed file analytics_raw.transactions .......................... [[32mINSERT 185141[0m in 134.00s]
[0m14:47:24.005848 [debug] [Thread-5 (]: Finished running node seed.patreon_analytics.transactions
[0m14:47:24.006872 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:47:24.007219 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:47:24.007653 [info ] [MainThread]: 
[0m14:47:24.008346 [info ] [MainThread]: Finished running 7 seeds in 0 hours 2 minutes and 35.24 seconds (155.24s).
[0m14:47:24.010206 [debug] [MainThread]: Command end result
[0m14:47:24.042598 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:47:24.046199 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:47:24.049762 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/run_results.json
[0m14:47:24.050007 [info ] [MainThread]: 
[0m14:47:24.050247 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:47:24.050420 [info ] [MainThread]: 
[0m14:47:24.050614 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m14:47:24.054647 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 157.03491, "process_in_blocks": "0", "process_kernel_time": 1.20933, "process_mem_max_rss": "706592768", "process_out_blocks": "0", "process_user_time": 91.42953}
[0m14:47:24.055006 [debug] [MainThread]: Command `dbt seed` succeeded at 14:47:24.054955 after 157.04 seconds
[0m14:47:24.055256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1234182f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124afaae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123813ce0>]}
[0m14:47:24.055470 [debug] [MainThread]: Flushing usage events
[0m14:47:24.454464 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:26.791752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058deb70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111514e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111514f20>]}


============================== 14:47:26.795090 | a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5 ==============================
[0m14:47:26.795090 [info ] [MainThread]: Running with dbt=1.11.0-rc3
[0m14:47:26.795477 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'no_print': 'None', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error': 'None', 'debug': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project', 'log_path': '/Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/logs', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'empty': 'False', 'log_format': 'default', 'printer_width': '80', 'fail_fast': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'write_json': 'True', 'target_path': 'None', 'partial_parse': 'True', 'quiet': 'False', 'send_anonymous_usage_stats': 'True'}
[0m14:47:27.283012 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:47:27.283334 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:47:27.283508 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:47:27.909329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1247f85c0>]}
[0m14:47:27.942200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144bc0e0>]}
[0m14:47:27.942721 [info ] [MainThread]: Registered adapter: databricks=1.11.3
[0m14:47:28.065487 [warn ] [MainThread]: [[33mWARNING[0m]: Use managed Iceberg tables when table_format is iceberg. When this flag is disabled, UniForm is used instead.
You may opt into the new behavior sooner by setting `flags.use_managed_iceberg` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:47:28.066062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12505b980>]}
[0m14:47:28.088852 [debug] [MainThread]: checksum: 0c6350755389a6ed721b17ac809f023d953b5a3e5903ed71b682e7badc0c55b0, vars: {}, profile: , target: , version: 1.11.0rc3
[0m14:47:28.242725 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:47:28.243040 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m14:47:28.243191 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:47:28.247799 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.patreon_analytics.intermediate
- models.patreon_analytics.marts.finance
[0m14:47:28.278685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12508b380>]}
[0m14:47:28.350481 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:47:28.353307 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:47:28.363018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125802960>]}
[0m14:47:28.363336 [info ] [MainThread]: Found 9 models, 36 data tests, 7 seeds, 4 metrics, 1126 macros, 1 semantic model
[0m14:47:28.363538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125807f20>]}
[0m14:47:28.365059 [info ] [MainThread]: 
[0m14:47:28.365311 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:47:28.365460 [info ] [MainThread]: 
[0m14:47:28.365813 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:47:28.365978 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:47:28.369632 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev) - Creating connection
[0m14:47:28.369934 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev'
[0m14:47:28.370197 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev) - Creating connection
[0m14:47:28.372140 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev) - Creating connection
[0m14:47:28.378579 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev"
[0m14:47:28.378920 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev'
[0m14:47:28.379180 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev'
[0m14:47:28.379378 [debug] [ThreadPool]: On list_patreon_dev: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
[0m14:47:28.380993 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev"
[0m14:47:28.382455 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev"
[0m14:47:28.382654 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:28.382819 [debug] [ThreadPool]: On list_patreon_dev: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
[0m14:47:28.383092 [debug] [ThreadPool]: On list_patreon_dev: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev"} */

    

  SHOW SCHEMAS IN `patreon_dev`


  
[0m14:47:28.383514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:28.383832 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:29.020501 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d67a-14d1-aadc-3aa11ed07580) - Created
[0m14:47:29.089043 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d685-1f60-93ac-ea6f101b1267) - Created
[0m14:47:29.092419 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d685-1f87-b52b-5254bb63bdf2) - Created
[0m14:47:29.366931 [debug] [ThreadPool]: SQL status: OK in 0.980 seconds
[0m14:47:29.376175 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d67a-14d1-aadc-3aa11ed07580, command-id=01f0db78-d690-1eae-95e5-8317e9829aa1) - Closing
[0m14:47:29.376606 [debug] [ThreadPool]: On list_patreon_dev: Close
[0m14:47:29.376787 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d67a-14d1-aadc-3aa11ed07580) - Closing
[0m14:47:29.421667 [debug] [ThreadPool]: SQL status: OK in 1.040 seconds
[0m14:47:29.422938 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d685-1f87-b52b-5254bb63bdf2, command-id=01f0db78-d69e-1332-9d58-9fde6eec46c5) - Closing
[0m14:47:29.423231 [debug] [ThreadPool]: SQL status: OK in 1.040 seconds
[0m14:47:29.423885 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d685-1f60-93ac-ea6f101b1267, command-id=01f0db78-d69d-16ff-bee0-61c74c2ed771) - Closing
[0m14:47:29.533646 [debug] [ThreadPool]: On list_patreon_dev: Close
[0m14:47:29.533958 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d685-1f87-b52b-5254bb63bdf2) - Closing
[0m14:47:29.709672 [debug] [ThreadPool]: On list_patreon_dev: Close
[0m14:47:29.710583 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d685-1f60-93ac-ea6f101b1267) - Closing
[0m14:47:29.888959 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_patreon_dev_analytics) - Creating connection
[0m14:47:29.890373 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_patreon_dev_analytics_staging) - Creating connection
[0m14:47:29.894760 [debug] [ThreadPool]: Acquiring new databricks connection 'create_patreon_dev_analytics'
[0m14:47:29.896165 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_patreon_dev_analytics_marts) - Creating connection
[0m14:47:29.899572 [debug] [ThreadPool]: Acquiring new databricks connection 'create_patreon_dev_analytics_staging'
[0m14:47:29.901597 [debug] [ThreadPool]: Creating schema "database: "patreon_dev"
schema: "analytics"
"
[0m14:47:29.902516 [debug] [ThreadPool]: Acquiring new databricks connection 'create_patreon_dev_analytics_marts'
[0m14:47:29.903279 [debug] [ThreadPool]: Creating schema "database: "patreon_dev"
schema: "analytics_staging"
"
[0m14:47:29.920385 [debug] [ThreadPool]: Creating schema "database: "patreon_dev"
schema: "analytics_marts"
"
[0m14:47:29.921188 [debug] [ThreadPool]: Using databricks connection "create_patreon_dev_analytics"
[0m14:47:29.926871 [debug] [ThreadPool]: Using databricks connection "create_patreon_dev_analytics_staging"
[0m14:47:29.928243 [debug] [ThreadPool]: Using databricks connection "create_patreon_dev_analytics_marts"
[0m14:47:29.928471 [debug] [ThreadPool]: On create_patreon_dev_analytics: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "create_patreon_dev_analytics"} */
create schema if not exists `patreon_dev`.`analytics`
  
[0m14:47:29.928646 [debug] [ThreadPool]: On create_patreon_dev_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "create_patreon_dev_analytics_staging"} */
create schema if not exists `patreon_dev`.`analytics_staging`
  
[0m14:47:29.928807 [debug] [ThreadPool]: On create_patreon_dev_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "create_patreon_dev_analytics_marts"} */
create schema if not exists `patreon_dev`.`analytics_marts`
  
[0m14:47:29.928950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:29.929081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:29.929212 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:30.556532 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d766-1500-88c9-7ac0dba836e9) - Created
[0m14:47:30.566274 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d766-17db-8503-55bec58906c0) - Created
[0m14:47:30.621552 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d76f-1698-a043-8787ba943e4d) - Created
[0m14:47:31.030235 [debug] [ThreadPool]: SQL status: OK in 1.100 seconds
[0m14:47:31.032529 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d766-1500-88c9-7ac0dba836e9, command-id=01f0db78-d77b-13ae-9fea-5681a3defdca) - Closing
[0m14:47:31.033317 [debug] [ThreadPool]: On create_patreon_dev_analytics_staging: Close
[0m14:47:31.033829 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d766-1500-88c9-7ac0dba836e9) - Closing
[0m14:47:31.057996 [debug] [ThreadPool]: SQL status: OK in 1.130 seconds
[0m14:47:31.058624 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d766-17db-8503-55bec58906c0, command-id=01f0db78-d77d-1189-9fe3-003edb0c4bec) - Closing
[0m14:47:31.115131 [debug] [ThreadPool]: SQL status: OK in 1.190 seconds
[0m14:47:31.115815 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d76f-1698-a043-8787ba943e4d, command-id=01f0db78-d787-1d3c-a614-061a40e4e354) - Closing
[0m14:47:31.190857 [debug] [ThreadPool]: On create_patreon_dev_analytics_marts: Close
[0m14:47:31.191195 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d766-17db-8503-55bec58906c0) - Closing
[0m14:47:31.359439 [debug] [ThreadPool]: On create_patreon_dev_analytics: Close
[0m14:47:31.360170 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d76f-1698-a043-8787ba943e4d) - Closing
[0m14:47:31.535344 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_raw) - Creating connection
[0m14:47:31.535987 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics) - Creating connection
[0m14:47:31.536269 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_raw'
[0m14:47:31.536661 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_staging) - Creating connection
[0m14:47:31.537213 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_patreon_dev_analytics_marts) - Creating connection
[0m14:47:31.537607 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics'
[0m14:47:31.538433 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_staging'
[0m14:47:31.539438 [debug] [ThreadPool]: Acquiring new databricks connection 'list_patreon_dev_analytics_marts'
[0m14:47:31.544938 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics"
[0m14:47:31.550009 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_raw"
[0m14:47:31.552689 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_staging"
[0m14:47:31.555289 [debug] [ThreadPool]: Using databricks connection "list_patreon_dev_analytics_marts"
[0m14:47:31.555689 [debug] [ThreadPool]: On list_patreon_dev_analytics: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics'

  
[0m14:47:31.556096 [debug] [ThreadPool]: On list_patreon_dev_analytics_raw: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_raw'

  
[0m14:47:31.556466 [debug] [ThreadPool]: On list_patreon_dev_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_staging"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_staging'

  
[0m14:47:31.556786 [debug] [ThreadPool]: On list_patreon_dev_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "connection_name": "list_patreon_dev_analytics_marts"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'patreon_dev' 
  AND table_schema = 'analytics_marts'

  
[0m14:47:31.557054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:31.557281 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:31.557502 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:31.557714 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:32.268510 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d86b-1210-a11a-affdf96fe193) - Created
[0m14:47:32.289800 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d86e-1a80-b9ab-9f85d1f2e6d6) - Created
[0m14:47:32.368161 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d87a-11b6-a7bd-3a19b8f3882d) - Created
[0m14:47:32.376002 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d879-1951-9a62-0554f71375c4) - Created
[0m14:47:32.721736 [debug] [ThreadPool]: SQL status: OK in 1.160 seconds
[0m14:47:32.725326 [debug] [ThreadPool]: SQL status: OK in 1.170 seconds
[0m14:47:32.727659 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d86b-1210-a11a-affdf96fe193, command-id=01f0db78-d880-18c0-81d2-2bae2a099b28) - Closing
[0m14:47:32.729077 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d86e-1a80-b9ab-9f85d1f2e6d6, command-id=01f0db78-d884-11db-9127-c8af443046e7) - Closing
[0m14:47:32.729567 [debug] [ThreadPool]: On list_patreon_dev_analytics_staging: Close
[0m14:47:32.730044 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d86b-1210-a11a-affdf96fe193) - Closing
[0m14:47:32.803774 [debug] [ThreadPool]: SQL status: OK in 1.250 seconds
[0m14:47:32.805544 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d87a-11b6-a7bd-3a19b8f3882d, command-id=01f0db78-d893-1092-8546-fd43c26bd36b) - Closing
[0m14:47:32.845325 [debug] [ThreadPool]: SQL status: OK in 1.290 seconds
[0m14:47:32.847325 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0db78-d879-1951-9a62-0554f71375c4, command-id=01f0db78-d893-1169-aa12-5eae959a7ae3) - Closing
[0m14:47:32.904228 [debug] [ThreadPool]: On list_patreon_dev_analytics: Close
[0m14:47:32.905102 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d86e-1a80-b9ab-9f85d1f2e6d6) - Closing
[0m14:47:33.066004 [debug] [ThreadPool]: On list_patreon_dev_analytics_marts: Close
[0m14:47:33.066354 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d87a-11b6-a7bd-3a19b8f3882d) - Closing
[0m14:47:33.245877 [debug] [ThreadPool]: On list_patreon_dev_analytics_raw: Close
[0m14:47:33.246300 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0db78-d879-1951-9a62-0554f71375c4) - Closing
[0m14:47:33.419713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12585f950>]}
[0m14:47:33.422324 [debug] [Thread-4 (]: Began running node model.patreon_analytics.metricflow_time_spine
[0m14:47:33.422828 [debug] [Thread-5 (]: Began running node model.patreon_analytics.stg_creators
[0m14:47:33.423151 [debug] [Thread-6 (]: Began running node model.patreon_analytics.stg_engagement_events
[0m14:47:33.423379 [debug] [Thread-7 (]: Began running node model.patreon_analytics.stg_patrons
[0m14:47:33.423757 [info ] [Thread-4 (]: 1 of 9 START sql table model analytics.metricflow_time_spine ................... [RUN]
[0m14:47:33.424468 [info ] [Thread-5 (]: 2 of 9 START sql view model analytics_staging.stg_creators ..................... [RUN]
[0m14:47:33.425083 [info ] [Thread-6 (]: 3 of 9 START sql view model analytics_staging.stg_engagement_events ............ [RUN]
[0m14:47:33.425614 [info ] [Thread-7 (]: 4 of 9 START sql view model analytics_staging.stg_patrons ...................... [RUN]
[0m14:47:33.426036 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.metricflow_time_spine) - Creating connection
[0m14:47:33.426518 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_creators) - Creating connection
[0m14:47:33.426954 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_engagement_events) - Creating connection
[0m14:47:33.427326 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_patrons) - Creating connection
[0m14:47:33.427632 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.patreon_analytics.metricflow_time_spine'
[0m14:47:33.427932 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_creators'
[0m14:47:33.428218 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_engagement_events'
[0m14:47:33.428450 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_patrons'
[0m14:47:33.428709 [debug] [Thread-4 (]: Began compiling node model.patreon_analytics.metricflow_time_spine
[0m14:47:33.428933 [debug] [Thread-5 (]: Began compiling node model.patreon_analytics.stg_creators
[0m14:47:33.429140 [debug] [Thread-6 (]: Began compiling node model.patreon_analytics.stg_engagement_events
[0m14:47:33.429343 [debug] [Thread-7 (]: Began compiling node model.patreon_analytics.stg_patrons
[0m14:47:33.436361 [debug] [Thread-5 (]: Writing injected SQL for node "model.patreon_analytics.stg_creators"
[0m14:47:33.439736 [debug] [Thread-6 (]: Writing injected SQL for node "model.patreon_analytics.stg_engagement_events"
[0m14:47:33.442840 [debug] [Thread-7 (]: Writing injected SQL for node "model.patreon_analytics.stg_patrons"
[0m14:47:33.470735 [debug] [Thread-4 (]: Using databricks connection "model.patreon_analytics.metricflow_time_spine"
[0m14:47:33.471366 [debug] [Thread-4 (]: On model.patreon_analytics.metricflow_time_spine: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.metricflow_time_spine"} */


        select timestampdiff(day, date_trunc('day', cast('2020-01-01' as timestamp)), date_trunc('day', cast('2030-12-31' as timestamp)))
[0m14:47:33.471797 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:47:33.473219 [debug] [Thread-5 (]: Began executing node model.patreon_analytics.stg_creators
[0m14:47:33.473560 [debug] [Thread-6 (]: Began executing node model.patreon_analytics.stg_engagement_events
[0m14:47:33.473856 [debug] [Thread-7 (]: Began executing node model.patreon_analytics.stg_patrons
[0m14:47:33.483554 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:47:33.485256 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:47:33.486800 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m14:47:33.488222 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:47:33.488696 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:47:33.489048 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:47:33.489284 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12580d850>]}
[0m14:47:33.489546 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12580d8b0>]}
[0m14:47:33.489818 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12580d940>]}
[0m14:47:33.497357 [debug] [Thread-6 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_engagement_events`
[0m14:47:33.497868 [debug] [Thread-5 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_creators`
[0m14:47:33.498487 [debug] [Thread-7 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_patrons`
[0m14:47:33.504956 [debug] [Thread-6 (]: Writing runtime sql for node "model.patreon_analytics.stg_engagement_events"
[0m14:47:33.505465 [debug] [Thread-5 (]: Writing runtime sql for node "model.patreon_analytics.stg_creators"
[0m14:47:33.505799 [debug] [Thread-7 (]: Writing runtime sql for node "model.patreon_analytics.stg_patrons"
[0m14:47:33.506510 [debug] [Thread-6 (]: Using databricks connection "model.patreon_analytics.stg_engagement_events"
[0m14:47:33.506756 [debug] [Thread-6 (]: On model.patreon_analytics.stg_engagement_events: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_engagement_events"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_engagement_events`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`engagement_events`
),

staged as (
    select
        event_id,
        patron_id,
        creator_id,
        post_id,
        event_type,
        event_at,
        
        -- Derived fields
        date_trunc('month', event_at) as event_month,
        date_trunc('day', event_at) as event_date,
        
        -- Engagement weighting (for composite scores)
        case event_type
            when 'view' then 1
            when 'like' then 3
            when 'comment' then 5
            when 'share' then 7
            else 1
        end as engagement_weight,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:33.507529 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:47:33.510440 [debug] [Thread-7 (]: Using databricks connection "model.patreon_analytics.stg_patrons"
[0m14:47:33.513173 [debug] [Thread-7 (]: On model.patreon_analytics.stg_patrons: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_patrons"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_patrons`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`patrons`
),

staged as (
    select
        patron_id,
        patron_name,
        email,
        country_code,
        created_at,
        first_pledge_at,
        coalesce(lifetime_spend_usd, 0) as lifetime_spend_usd,
        coalesce(status, 'active') as status,
        
        -- Derived fields
        datediff(month, created_at, current_timestamp()) as account_age_months,
        case 
            when lifetime_spend_usd >= 1000 then 'whale'
            when lifetime_spend_usd >= 500 then 'high_value'
            when lifetime_spend_usd >= 100 then 'regular'
            else 'casual'
        end as patron_value_tier,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:33.516358 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:47:33.511909 [debug] [Thread-5 (]: Using databricks connection "model.patreon_analytics.stg_creators"
[0m14:47:33.588518 [debug] [Thread-5 (]: On model.patreon_analytics.stg_creators: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_creators"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_creators`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`creators`
),

staged as (
    select
        creator_id,
        creator_name,
        email,
        category,
        subcategory,
        country_code,
        coalesce(currency_code, 'USD') as currency_code,
        coalesce(plan_type, 'pro') as plan_type,
        coalesce(is_nsfw, false) as is_nsfw,
        coalesce(is_verified, false) as is_verified,
        created_at,
        first_pledge_received_at,
        last_post_at,
        coalesce(status, 'active') as status,
        
        -- Derived fields
        datediff(day, created_at, coalesce(first_pledge_received_at, current_timestamp())) as days_to_first_pledge,
        datediff(month, created_at, current_timestamp()) as account_age_months,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:33.600476 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:47:34.164968 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db78-d98b-1ee8-b1d8-0b2518c2d677) - Created
[0m14:47:34.216566 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-d994-15b7-b693-81ba3571b6d8) - Created
[0m14:47:34.292294 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-d9a0-1089-a831-bb63392fed89) - Created
[0m14:47:34.298890 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db78-d9a0-13a4-b74e-a48a212818de) - Created
[0m14:47:34.476172 [debug] [Thread-4 (]: SQL status: OK in 1.000 seconds
[0m14:47:34.482270 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-d98b-1ee8-b1d8-0b2518c2d677, command-id=01f0db78-d9a1-1fe2-b214-ce924e1eca4a) - Closing
[0m14:47:34.527915 [debug] [Thread-4 (]: Writing injected SQL for node "model.patreon_analytics.metricflow_time_spine"
[0m14:47:34.528764 [debug] [Thread-4 (]: Began executing node model.patreon_analytics.metricflow_time_spine
[0m14:47:34.540126 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m14:47:34.558126 [debug] [Thread-4 (]: Writing runtime sql for node "model.patreon_analytics.metricflow_time_spine"
[0m14:47:34.558811 [debug] [Thread-4 (]: Using databricks connection "model.patreon_analytics.metricflow_time_spine"
[0m14:47:34.559242 [debug] [Thread-4 (]: On model.patreon_analytics.metricflow_time_spine: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.metricflow_time_spine"} */

  
    
        create or replace table `patreon_dev`.`analytics`.`metricflow_time_spine`
      
      
    using delta
  
      
      
      
      
      
      
      
      as
      with days as (
    
    
with base_dates as (
    
    with date_spine as
(

    





with rawdata as (

    

    

    with p as (
        select 0 as generated_number union all select 1
    ), unioned as (

    select

    
    p0.generated_number * power(2, 0)
     + 
    
    p1.generated_number * power(2, 1)
     + 
    
    p2.generated_number * power(2, 2)
     + 
    
    p3.generated_number * power(2, 3)
     + 
    
    p4.generated_number * power(2, 4)
     + 
    
    p5.generated_number * power(2, 5)
     + 
    
    p6.generated_number * power(2, 6)
     + 
    
    p7.generated_number * power(2, 7)
     + 
    
    p8.generated_number * power(2, 8)
     + 
    
    p9.generated_number * power(2, 9)
     + 
    
    p10.generated_number * power(2, 10)
     + 
    
    p11.generated_number * power(2, 11)
    
    
    + 1
    as generated_number

    from

    
    p as p0
     cross join 
    
    p as p1
     cross join 
    
    p as p2
     cross join 
    
    p as p3
     cross join 
    
    p as p4
     cross join 
    
    p as p5
     cross join 
    
    p as p6
     cross join 
    
    p as p7
     cross join 
    
    p as p8
     cross join 
    
    p as p9
     cross join 
    
    p as p10
     cross join 
    
    p as p11
    
    

    )

    select *
    from unioned
    where generated_number <= 4017
    order by generated_number



),

all_periods as (

    select (
        timestampadd(day, (row_number() over (order by 1) - 1), cast('2020-01-01' as timestamp))
    ) as date_day
    from rawdata

),

filtered as (

    select *
    from all_periods
    where date_day <= cast('2030-12-31' as timestamp)

)

select * from filtered



)
select
    cast(d.date_day as timestamp) as date_day
from
    date_spine d


),
dates_with_prior_year_dates as (

    select
        cast(d.date_day as date) as date_day,
        cast(timestampadd(year, -1, d.date_day) as date) as prior_year_date_day,
        cast(timestampadd(day, -364, d.date_day) as date) as prior_year_over_year_date_day
    from
    	base_dates d

)
select
    d.date_day,
    cast(timestampadd(day, -1, d.date_day) as date) as prior_date_day,
    cast(timestampadd(day, 1, d.date_day) as date) as next_date_day,
    d.prior_year_date_day as prior_year_date_day,
    d.prior_year_over_year_date_day,
    date_part('dayofweek', d.date_day) as day_of_week,
    date_part('dayofweek_iso', d.date_day) as day_of_week_iso,
    date_format(d.date_day, 'EEEE') as day_of_week_name,
    date_format(d.date_day, 'E') as day_of_week_name_short,
    date_part('day', d.date_day) as day_of_month,
    dayofyear(d.date_day) as day_of_year,

    cast(date_trunc('week', d.date_day) as date) as week_start_date,
    cast(
        timestampadd(day, -1, timestampadd(week, 1, date_trunc('week', d.date_day)))
        as date) as week_end_date,
    cast(date_trunc('week', d.prior_year_over_year_date_day) as date) as prior_year_week_start_date,
    cast(
        timestampadd(day, -1, timestampadd(week, 1, date_trunc('week', d.prior_year_over_year_date_day)))
        as date) as prior_year_week_end_date,
    cast(date_part('week', d.date_day) as integer) as week_of_year,

    cast(date_trunc('week', d.date_day) as date) as iso_week_start_date,
    cast(timestampadd(day, 6, cast(date_trunc('week', d.date_day) as date)) as date) as iso_week_end_date,
    cast(date_trunc('week', d.prior_year_over_year_date_day) as date) as prior_year_iso_week_start_date,
    cast(timestampadd(day, 6, cast(date_trunc('week', d.prior_year_over_year_date_day) as date)) as date) as prior_year_iso_week_end_date,
    cast(date_part('week', d.date_day) as integer) as iso_week_of_year,

    cast(date_part('week', d.prior_year_over_year_date_day) as integer) as prior_year_week_of_year,
    cast(date_part('week', d.prior_year_over_year_date_day) as integer) as prior_year_iso_week_of_year,

    cast(date_part('month', d.date_day) as integer) as month_of_year,
    date_format(d.date_day, 'MMMM')  as month_name,
    date_format(d.date_day, 'MMM')  as month_name_short,

    cast(date_trunc('month', d.date_day) as date) as month_start_date,
    cast(cast(
        timestampadd(day, -1, timestampadd(month, 1, date_trunc('month', d.date_day)))
        as date) as date) as month_end_date,

    cast(date_trunc('month', d.prior_year_date_day) as date) as prior_year_month_start_date,
    cast(cast(
        timestampadd(day, -1, timestampadd(month, 1, date_trunc('month', d.prior_year_date_day)))
        as date) as date) as prior_year_month_end_date,

    cast(date_part('quarter', d.date_day) as integer) as quarter_of_year,
    cast(date_trunc('quarter', d.date_day) as date) as quarter_start_date,
    cast(cast(
        timestampadd(day, -1, timestampadd(quarter, 1, date_trunc('quarter', d.date_day)))
        as date) as date) as quarter_end_date,

    cast(date_part('year', d.date_day) as integer) as year_number,
    cast(date_trunc('year', d.date_day) as date) as year_start_date,
    cast(cast(
        timestampadd(day, -1, timestampadd(year, 1, date_trunc('year', d.date_day)))
        as date) as date) as year_end_date
from
    dates_with_prior_year_dates d
order by 1


)

select
    date_day as date_day
from days
  
[0m14:47:34.908121 [debug] [Thread-5 (]: SQL status: OK in 1.320 seconds
[0m14:47:34.910135 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-d994-15b7-b693-81ba3571b6d8, command-id=01f0db78-d9aa-122f-9f2b-6ac6b946cd55) - Closing
[0m14:47:34.920247 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:47:34.923251 [debug] [Thread-5 (]: On model.patreon_analytics.stg_creators: Close
[0m14:47:34.923602 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-d994-15b7-b693-81ba3571b6d8) - Closing
[0m14:47:34.928927 [debug] [Thread-7 (]: SQL status: OK in 1.410 seconds
[0m14:47:34.929727 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0db78-d9a0-13a4-b74e-a48a212818de, command-id=01f0db78-d9b9-148c-b913-db5aca17e96d) - Closing
[0m14:47:34.930201 [debug] [Thread-7 (]: Applying tags to relation None
[0m14:47:35.023600 [debug] [Thread-6 (]: SQL status: OK in 1.520 seconds
[0m14:47:35.025405 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-d9a0-1089-a831-bb63392fed89, command-id=01f0db78-d9b8-1578-863b-174aa4f3904c) - Closing
[0m14:47:35.026449 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:47:35.083300 [debug] [Thread-7 (]: On model.patreon_analytics.stg_patrons: Close
[0m14:47:35.084461 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db78-d9a0-13a4-b74e-a48a212818de) - Closing
[0m14:47:35.252342 [debug] [Thread-6 (]: On model.patreon_analytics.stg_engagement_events: Close
[0m14:47:35.252674 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-d9a0-1089-a831-bb63392fed89) - Closing
[0m14:47:35.428363 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12580cc20>]}
[0m14:47:35.428855 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9ff20>]}
[0m14:47:35.429208 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259327e0>]}
[0m14:47:35.429831 [info ] [Thread-7 (]: 4 of 9 OK created sql view model analytics_staging.stg_patrons ................. [[32mOK[0m in 2.00s]
[0m14:47:35.430475 [info ] [Thread-5 (]: 2 of 9 OK created sql view model analytics_staging.stg_creators ................ [[32mOK[0m in 2.00s]
[0m14:47:35.432066 [debug] [Thread-7 (]: Finished running node model.patreon_analytics.stg_patrons
[0m14:47:35.430993 [info ] [Thread-6 (]: 3 of 9 OK created sql view model analytics_staging.stg_engagement_events ....... [[32mOK[0m in 2.00s]
[0m14:47:35.432710 [debug] [Thread-5 (]: Finished running node model.patreon_analytics.stg_creators
[0m14:47:35.433087 [debug] [Thread-7 (]: Began running node model.patreon_analytics.stg_pledges
[0m14:47:35.433783 [debug] [Thread-6 (]: Finished running node model.patreon_analytics.stg_engagement_events
[0m14:47:35.434280 [debug] [Thread-5 (]: Began running node model.patreon_analytics.stg_posts
[0m14:47:35.434798 [info ] [Thread-7 (]: 5 of 9 START sql view model analytics_staging.stg_pledges ...................... [RUN]
[0m14:47:35.435252 [debug] [Thread-6 (]: Began running node model.patreon_analytics.stg_tiers
[0m14:47:35.435718 [info ] [Thread-5 (]: 6 of 9 START sql view model analytics_staging.stg_posts ........................ [RUN]
[0m14:47:35.436300 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_pledges) - Creating connection
[0m14:47:35.436713 [info ] [Thread-6 (]: 7 of 9 START sql view model analytics_staging.stg_tiers ........................ [RUN]
[0m14:47:35.437145 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_posts) - Creating connection
[0m14:47:35.437476 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_pledges'
[0m14:47:35.437884 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_tiers) - Creating connection
[0m14:47:35.438210 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_posts'
[0m14:47:35.438507 [debug] [Thread-7 (]: Began compiling node model.patreon_analytics.stg_pledges
[0m14:47:35.438809 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_tiers'
[0m14:47:35.439088 [debug] [Thread-5 (]: Began compiling node model.patreon_analytics.stg_posts
[0m14:47:35.443327 [debug] [Thread-7 (]: Writing injected SQL for node "model.patreon_analytics.stg_pledges"
[0m14:47:35.443741 [debug] [Thread-6 (]: Began compiling node model.patreon_analytics.stg_tiers
[0m14:47:35.533884 [debug] [Thread-6 (]: Writing injected SQL for node "model.patreon_analytics.stg_tiers"
[0m14:47:35.540419 [debug] [Thread-5 (]: Writing injected SQL for node "model.patreon_analytics.stg_posts"
[0m14:47:35.540744 [debug] [Thread-7 (]: Began executing node model.patreon_analytics.stg_pledges
[0m14:47:35.542212 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m14:47:35.542742 [debug] [Thread-7 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_pledges`
[0m14:47:35.543079 [debug] [Thread-7 (]: Writing runtime sql for node "model.patreon_analytics.stg_pledges"
[0m14:47:35.543294 [debug] [Thread-6 (]: Began executing node model.patreon_analytics.stg_tiers
[0m14:47:35.544709 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:47:35.545156 [debug] [Thread-6 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_tiers`
[0m14:47:35.545511 [debug] [Thread-6 (]: Writing runtime sql for node "model.patreon_analytics.stg_tiers"
[0m14:47:35.545976 [debug] [Thread-5 (]: Began executing node model.patreon_analytics.stg_posts
[0m14:47:35.546223 [debug] [Thread-7 (]: Using databricks connection "model.patreon_analytics.stg_pledges"
[0m14:47:35.547929 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:47:35.548257 [debug] [Thread-7 (]: On model.patreon_analytics.stg_pledges: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_pledges"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_pledges`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`pledges`
),

staged as (
    select
        pledge_id,
        patron_id,
        creator_id,
        tier_id,
        pledge_amount_usd,
        pledge_status,
        coalesce(is_first_pledge, false) as is_first_pledge,
        started_at,
        ended_at,
        pause_started_at,
        churn_reason,
        
        -- Derived fields
        date_trunc('month', started_at) as pledge_month,
        case 
            when pledge_status = 'active' then null
            else datediff(day, started_at, coalesce(ended_at, current_timestamp()))
        end as pledge_duration_days,
        
        -- Is currently active (for point-in-time analysis)
        case 
            when pledge_status = 'active' and pause_started_at is null then true
            else false
        end as is_currently_active,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:35.548812 [debug] [Thread-5 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_posts`
[0m14:47:35.549033 [debug] [Thread-6 (]: Using databricks connection "model.patreon_analytics.stg_tiers"
[0m14:47:35.549344 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:47:35.549772 [debug] [Thread-5 (]: Writing runtime sql for node "model.patreon_analytics.stg_posts"
[0m14:47:35.550057 [debug] [Thread-6 (]: On model.patreon_analytics.stg_tiers: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_tiers"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_tiers`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`tiers`
),

staged as (
    select
        tier_id,
        creator_id,
        tier_name,
        tier_rank,
        price_usd,
        description,
        coalesce(is_active, true) as is_active,
        created_at,
        archived_at,
        
        -- Price bucket for analysis
        case 
            when price_usd <= 5 then 'micro'
            when price_usd <= 15 then 'standard'
            when price_usd <= 30 then 'premium'
            else 'whale'
        end as price_bucket,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:35.550464 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:47:35.551168 [debug] [Thread-5 (]: Using databricks connection "model.patreon_analytics.stg_posts"
[0m14:47:35.551506 [debug] [Thread-5 (]: On model.patreon_analytics.stg_posts: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_posts"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_posts`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`posts`
),

staged as (
    select
        post_id,
        creator_id,
        title,
        post_type,
        access_level,
        minimum_tier_id,
        published_at,
        coalesce(is_pinned, false) as is_pinned,
        
        -- Derived fields
        date_trunc('month', published_at) as published_month,
        date_trunc('day', published_at) as published_date,
        
        -- Content categorization
        case 
            when access_level = 'public' then 'free'
            when access_level = 'patrons_only' then 'paywalled'
            when access_level = 'tier_specific' then 'premium'
            else 'unknown'
        end as content_access_type,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:35.551766 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:47:36.154464 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-dabc-1cf3-9138-43fa94eb7b9c) - Created
[0m14:47:36.232013 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-dac8-1544-917e-fa69b2aa9e65) - Created
[0m14:47:36.238367 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db78-dac9-16f0-a747-a9421edaefe4) - Created
[0m14:47:36.740896 [debug] [Thread-5 (]: SQL status: OK in 1.190 seconds
[0m14:47:36.743449 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-dabc-1cf3-9138-43fa94eb7b9c, command-id=01f0db78-dad1-15f9-bd9b-0df5e096e4ab) - Closing
[0m14:47:36.744737 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:47:36.746416 [debug] [Thread-5 (]: On model.patreon_analytics.stg_posts: Close
[0m14:47:36.747083 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-dabc-1cf3-9138-43fa94eb7b9c) - Closing
[0m14:47:36.833290 [debug] [Thread-6 (]: SQL status: OK in 1.280 seconds
[0m14:47:36.834115 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-dac8-1544-917e-fa69b2aa9e65, command-id=01f0db78-dae2-1b72-aca9-955724fdd31e) - Closing
[0m14:47:36.834587 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:47:36.858938 [debug] [Thread-7 (]: SQL status: OK in 1.310 seconds
[0m14:47:36.859721 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0db78-dac9-16f0-a747-a9421edaefe4, command-id=01f0db78-dae0-1652-8500-8e0064c1d97b) - Closing
[0m14:47:36.860169 [debug] [Thread-7 (]: Applying tags to relation None
[0m14:47:36.910432 [debug] [Thread-6 (]: On model.patreon_analytics.stg_tiers: Close
[0m14:47:36.910778 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-dac8-1544-917e-fa69b2aa9e65) - Closing
[0m14:47:37.076087 [debug] [Thread-7 (]: On model.patreon_analytics.stg_pledges: Close
[0m14:47:37.076410 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0db78-dac9-16f0-a747-a9421edaefe4) - Closing
[0m14:47:37.250580 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125999d30>]}
[0m14:47:37.252534 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1258e2f30>]}
[0m14:47:37.253683 [info ] [Thread-6 (]: 7 of 9 OK created sql view model analytics_staging.stg_tiers ................... [[32mOK[0m in 1.81s]
[0m14:47:37.254466 [debug] [Thread-6 (]: Finished running node model.patreon_analytics.stg_tiers
[0m14:47:37.251971 [info ] [Thread-5 (]: 6 of 9 OK created sql view model analytics_staging.stg_posts ................... [[32mOK[0m in 1.81s]
[0m14:47:37.257231 [debug] [Thread-5 (]: Finished running node model.patreon_analytics.stg_posts
[0m14:47:37.255778 [debug] [Thread-6 (]: Began running node model.patreon_analytics.stg_transactions
[0m14:47:37.256382 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1258e1af0>]}
[0m14:47:37.258795 [info ] [Thread-6 (]: 8 of 9 START sql view model analytics_staging.stg_transactions ................. [RUN]
[0m14:47:37.260822 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.stg_transactions) - Creating connection
[0m14:47:37.261378 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.patreon_analytics.stg_transactions'
[0m14:47:37.260089 [info ] [Thread-7 (]: 5 of 9 OK created sql view model analytics_staging.stg_pledges ................. [[32mOK[0m in 1.82s]
[0m14:47:37.262080 [debug] [Thread-6 (]: Began compiling node model.patreon_analytics.stg_transactions
[0m14:47:37.262467 [debug] [Thread-7 (]: Finished running node model.patreon_analytics.stg_pledges
[0m14:47:37.265149 [debug] [Thread-6 (]: Writing injected SQL for node "model.patreon_analytics.stg_transactions"
[0m14:47:37.265843 [debug] [Thread-6 (]: Began executing node model.patreon_analytics.stg_transactions
[0m14:47:37.273032 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:47:37.274369 [debug] [Thread-6 (]: Creating view `patreon_dev`.`analytics_staging`.`stg_transactions`
[0m14:47:37.275114 [debug] [Thread-6 (]: Writing runtime sql for node "model.patreon_analytics.stg_transactions"
[0m14:47:37.275899 [debug] [Thread-6 (]: Using databricks connection "model.patreon_analytics.stg_transactions"
[0m14:47:37.276349 [debug] [Thread-6 (]: On model.patreon_analytics.stg_transactions: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.stg_transactions"} */

  
  
  create or replace view `patreon_dev`.`analytics_staging`.`stg_transactions`
  
  as (
    with source as (
    select * from `patreon_dev`.`analytics_raw`.`transactions`
),

staged as (
    select
        transaction_id,
        pledge_id,
        patron_id,
        creator_id,
        transaction_type,
        transaction_status,
        gross_amount_usd,
        platform_fee_usd,
        processing_fee_usd,
        net_amount_usd,
        payment_method,
        failure_reason,
        transaction_at,
        
        -- Derived fields
        date_trunc('month', transaction_at) as transaction_month,
        date_trunc('day', transaction_at) as transaction_date,
        
        -- Fee analysis
        case 
            when gross_amount_usd > 0 and transaction_status = 'succeeded'
            then round((platform_fee_usd / gross_amount_usd) * 100, 2)
            else null
        end as platform_fee_rate_pct,
        
        case 
            when gross_amount_usd > 0 and transaction_status = 'succeeded'
            then round((processing_fee_usd / gross_amount_usd) * 100, 2)
            else null
        end as processing_fee_rate_pct,
        
        -- Success flag
        case when transaction_status = 'succeeded' then 1 else 0 end as is_successful,
        
        current_timestamp() as _stg_loaded_at
        
    from source
)

select * from staged
  )

[0m14:47:37.276637 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:47:37.822640 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-dbba-18e6-9624-fcac11232a62) - Created
[0m14:47:38.537339 [debug] [Thread-6 (]: SQL status: OK in 1.260 seconds
[0m14:47:38.539055 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f0db78-dbba-18e6-9624-fcac11232a62, command-id=01f0db78-dbd0-1270-a8ed-b4a1d130aba7) - Closing
[0m14:47:38.540045 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:47:38.541313 [debug] [Thread-6 (]: On model.patreon_analytics.stg_transactions: Close
[0m14:47:38.541873 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f0db78-dbba-18e6-9624-fcac11232a62) - Closing
[0m14:47:38.696605 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1258f7b30>]}
[0m14:47:38.698007 [info ] [Thread-6 (]: 8 of 9 OK created sql view model analytics_staging.stg_transactions ............ [[32mOK[0m in 1.44s]
[0m14:47:38.698875 [debug] [Thread-6 (]: Finished running node model.patreon_analytics.stg_transactions
[0m14:47:38.699769 [debug] [Thread-5 (]: Began running node model.patreon_analytics.fct_creator_monthly_performance
[0m14:47:38.700662 [info ] [Thread-5 (]: 9 of 9 START sql table model analytics_marts.fct_creator_monthly_performance ... [RUN]
[0m14:47:38.701585 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.patreon_analytics.fct_creator_monthly_performance) - Creating connection
[0m14:47:38.702170 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.patreon_analytics.fct_creator_monthly_performance'
[0m14:47:38.702693 [debug] [Thread-5 (]: Began compiling node model.patreon_analytics.fct_creator_monthly_performance
[0m14:47:38.724280 [debug] [Thread-5 (]: Writing injected SQL for node "model.patreon_analytics.fct_creator_monthly_performance"
[0m14:47:38.725860 [debug] [Thread-5 (]: Began executing node model.patreon_analytics.fct_creator_monthly_performance
[0m14:47:38.728555 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:47:38.730137 [debug] [Thread-5 (]: Writing runtime sql for node "model.patreon_analytics.fct_creator_monthly_performance"
[0m14:47:38.731464 [debug] [Thread-5 (]: Using databricks connection "model.patreon_analytics.fct_creator_monthly_performance"
[0m14:47:38.732487 [debug] [Thread-5 (]: On model.patreon_analytics.fct_creator_monthly_performance: /* {"app": "dbt", "dbt_version": "1.11.0rc3", "dbt_databricks_version": "1.11.3", "databricks_sql_connector_version": "4.1.3", "profile_name": "patreon_databricks", "target_name": "dev", "node_id": "model.patreon_analytics.fct_creator_monthly_performance"} */

  
    
        create or replace table `patreon_dev`.`analytics_marts`.`fct_creator_monthly_performance`
      
      
    using delta
  
      
      
      
      
      
      
      
      as
      with creators as (
    select * from `patreon_dev`.`analytics_staging`.`stg_creators`
),

pledges as (
    select * from `patreon_dev`.`analytics_staging`.`stg_pledges`
),

transactions as (
    select * from `patreon_dev`.`analytics_staging`.`stg_transactions`
),

tiers as (
    select * from `patreon_dev`.`analytics_staging`.`stg_tiers`
),

posts as (
    select * from `patreon_dev`.`analytics_staging`.`stg_posts`
),

engagement as (
    select * from `patreon_dev`.`analytics_staging`.`stg_engagement_events`
),

-- Generate month spine from earliest pledge to current month
months as (
    select distinct date_trunc('month', transaction_at)::date as month_start_date
    from transactions
),

-- Create creator-month combinations
creator_months as (
    select 
        c.creator_id,
        m.month_start_date,
        md5(cast(concat(coalesce(cast(c.creator_id as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(m.month_start_date as string), '_dbt_utils_surrogate_key_null_')) as string)) as creator_month_key
    from creators c
    cross join months m
    where m.month_start_date >= date_trunc('month', c.first_pledge_received_at)
),

-- Monthly pledge metrics
pledge_metrics as (
    select
        p.creator_id,
        date_trunc('month', t.transaction_at)::date as month_start_date,
        
        -- Patron counts
        count(distinct p.patron_id) as total_patrons,
        count(distinct case when p.pledge_status = 'active' then p.patron_id end) as active_patrons,
        count(distinct case when p.is_first_pledge = true then p.patron_id end) as new_patrons,
        count(distinct case when p.pledge_status = 'churned' then p.patron_id end) as churned_patrons,
        
        -- MRR
        sum(case when p.pledge_status = 'active' then p.pledge_amount_usd else 0 end) as gross_mrr_usd,
        sum(case when p.is_first_pledge = true then p.pledge_amount_usd else 0 end) as new_mrr_usd,
        sum(case when p.pledge_status = 'churned' then p.pledge_amount_usd else 0 end) as churned_mrr_usd,
        
        -- Tier distribution
        count(distinct case when ti.tier_rank = 1 then p.patron_id end) as tier_1_patrons,
        count(distinct case when ti.tier_rank = 2 then p.patron_id end) as tier_2_patrons,
        count(distinct case when ti.tier_rank >= 3 then p.patron_id end) as tier_3_plus_patrons,
        
        -- ARPP
        avg(p.pledge_amount_usd) as avg_pledge_amount_usd
        
    from pledges p
    inner join transactions t on p.pledge_id = t.pledge_id
    left join tiers ti on p.tier_id = ti.tier_id
    group by 1, 2
),

-- Monthly revenue (actual collections)
revenue_metrics as (
    select
        creator_id,
        date_trunc('month', transaction_at)::date as month_start_date,
        
        sum(case when transaction_status = 'succeeded' then gross_amount_usd else 0 end) as gross_revenue_usd,
        sum(case when transaction_status = 'succeeded' then platform_fee_usd else 0 end) as platform_fees_usd,
        sum(case when transaction_status = 'succeeded' then processing_fee_usd else 0 end) as processing_fees_usd,
        sum(case when transaction_status = 'succeeded' then net_amount_usd else 0 end) as net_creator_earnings_usd,
        
        count(case when transaction_status = 'succeeded' then 1 end) as successful_transactions,
        count(case when transaction_status = 'failed' then 1 end) as failed_transactions,
        sum(case when transaction_status = 'failed' then gross_amount_usd else 0 end) as declined_amount_usd
        
    from transactions
    where transaction_type = 'pledge_payment'
    group by 1, 2
),

-- Monthly content metrics
content_metrics as (
    select
        creator_id,
        published_month as month_start_date,
        
        count(distinct post_id) as posts_published,
        count(distinct case when content_access_type = 'paywalled' then post_id end) as paywalled_posts,
        count(distinct case when content_access_type = 'free' then post_id end) as free_posts
        
    from posts
    group by 1, 2
),

-- Monthly engagement metrics
engagement_metrics as (
    select
        creator_id,
        event_month as month_start_date,
        
        count(case when event_type = 'view' then 1 end) as total_views,
        count(case when event_type = 'like' then 1 end) as total_likes,
        count(case when event_type = 'comment' then 1 end) as total_comments,
        count(distinct patron_id) as engaged_patrons,
        sum(engagement_weight) as total_engagement_score
        
    from engagement
    group by 1, 2
),

-- Previous month for growth calculations
lagged as (
    select
        creator_id,
        month_start_date,
        lag(gross_mrr_usd) over (partition by creator_id order by month_start_date) as prev_mrr,
        lag(active_patrons) over (partition by creator_id order by month_start_date) as prev_patrons
    from pledge_metrics
)

select
    cm.creator_month_key,
    cm.creator_id,
    cm.month_start_date,
    
    -- Creator attributes
    c.creator_name,
    c.category as creator_category,
    c.plan_type,
    c.country_code as creator_country,
    
    -- Patron metrics
    coalesce(pm.total_patrons, 0) as total_patrons,
    coalesce(pm.active_patrons, 0) as active_patrons,
    coalesce(pm.new_patrons, 0) as new_patrons,
    coalesce(pm.churned_patrons, 0) as churned_patrons,
    coalesce(pm.active_patrons, 0) - coalesce(l.prev_patrons, 0) as net_patron_change,
    
    case 
        when coalesce(l.prev_patrons, 0) > 0 
        then round((pm.churned_patrons * 100.0 / l.prev_patrons), 2)
        else 0 
    end as patron_churn_rate_pct,
    
    -- MRR metrics
    coalesce(pm.gross_mrr_usd, 0) as gross_mrr_usd,
    coalesce(pm.new_mrr_usd, 0) as new_mrr_usd,
    coalesce(pm.churned_mrr_usd, 0) as churned_mrr_usd,
    coalesce(pm.gross_mrr_usd, 0) - coalesce(l.prev_mrr, 0) as mrr_change_usd,
    
    case 
        when coalesce(l.prev_mrr, 0) > 0 
        then round(((pm.gross_mrr_usd - l.prev_mrr) * 100.0 / l.prev_mrr), 2)
        else null 
    end as mrr_growth_rate_pct,
    
    -- Revenue metrics
    coalesce(rm.gross_revenue_usd, 0) as gross_revenue_usd,
    coalesce(rm.platform_fees_usd, 0) as platform_fees_usd,
    coalesce(rm.processing_fees_usd, 0) as processing_fees_usd,
    coalesce(rm.net_creator_earnings_usd, 0) as net_creator_earnings_usd,
    
    case 
        when coalesce(pm.gross_mrr_usd, 0) > 0 
        then round((rm.gross_revenue_usd * 100.0 / pm.gross_mrr_usd), 2)
        else null 
    end as collection_rate_pct,
    
    -- Payment health
    coalesce(rm.successful_transactions, 0) as successful_transactions,
    coalesce(rm.failed_transactions, 0) as failed_transactions,
    coalesce(rm.declined_amount_usd, 0) as declined_amount_usd,
    
    case 
        when coalesce(rm.successful_transactions, 0) + coalesce(rm.failed_transactions, 0) > 0
        then round((rm.failed_transactions * 100.0 / (rm.successful_transactions + rm.failed_transactions)), 2)
        else 0 
    end as decline_rate_pct,
    
    -- Tier distribution
    coalesce(pm.tier_1_patrons, 0) as tier_1_patrons,
    coalesce(pm.tier_2_patrons, 0) as tier_2_patrons,
    coalesce(pm.tier_3_plus_patrons, 0) as tier_3_plus_patrons,
    coalesce(pm.avg_pledge_amount_usd, 0) as avg_pledge_amount_usd,
    
    -- Content metrics
    coalesce(cnt.posts_published, 0) as posts_published,
    coalesce(cnt.paywalled_posts, 0) as paywalled_posts,
    coalesce(cnt.free_posts, 0) as free_posts,
    
    -- Engagement metrics
    coalesce(eng.total_views, 0) as total_views,
    coalesce(eng.total_likes, 0) as total_likes,
    coalesce(eng.total_comments, 0) as total_comments,
    coalesce(eng.engaged_patrons, 0) as engaged_patrons,
    coalesce(eng.total_engagement_score, 0) as total_engagement_score,
    
    case 
        when coalesce(pm.active_patrons, 0) > 0 
        then round((eng.engaged_patrons * 100.0 / pm.active_patrons), 2)
        else null 
    end as patron_engagement_rate_pct,
    
    current_timestamp() as updated_at

from creator_months cm
left join creators c on cm.creator_id = c.creator_id
left join pledge_metrics pm on cm.creator_id = pm.creator_id and cm.month_start_date = pm.month_start_date
left join revenue_metrics rm on cm.creator_id = rm.creator_id and cm.month_start_date = rm.month_start_date
left join content_metrics cnt on cm.creator_id = cnt.creator_id and cm.month_start_date = cnt.month_start_date
left join engagement_metrics eng on cm.creator_id = eng.creator_id and cm.month_start_date = eng.month_start_date
left join lagged l on cm.creator_id = l.creator_id and cm.month_start_date = l.month_start_date
  
[0m14:47:38.733149 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:47:39.060432 [debug] [Thread-4 (]: SQL status: OK in 4.500 seconds
[0m14:47:39.061130 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f0db78-d98b-1ee8-b1d8-0b2518c2d677, command-id=01f0db78-d9de-1471-99d5-eae4e4bd2294) - Closing
[0m14:47:39.061520 [debug] [Thread-4 (]: Applying tags to relation None
[0m14:47:39.075000 [debug] [Thread-4 (]: On model.patreon_analytics.metricflow_time_spine: Close
[0m14:47:39.075384 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f0db78-d98b-1ee8-b1d8-0b2518c2d677) - Closing
[0m14:47:39.238466 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259c3f80>]}
[0m14:47:39.239045 [info ] [Thread-4 (]: 1 of 9 OK created sql table model analytics.metricflow_time_spine .............. [[32mOK[0m in 5.81s]
[0m14:47:39.239394 [debug] [Thread-4 (]: Finished running node model.patreon_analytics.metricflow_time_spine
[0m14:47:39.267163 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-dc96-16a7-9475-f9c6419b9093) - Created
[0m14:47:47.372714 [debug] [Thread-5 (]: SQL status: OK in 8.640 seconds
[0m14:47:47.378648 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f0db78-dc96-16a7-9475-f9c6419b9093, command-id=01f0db78-dcac-11fc-a123-79d045cbfa7d) - Closing
[0m14:47:47.567985 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:47:47.570296 [debug] [Thread-5 (]: On model.patreon_analytics.fct_creator_monthly_performance: Close
[0m14:47:47.570622 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f0db78-dc96-16a7-9475-f9c6419b9093) - Closing
[0m14:47:47.738427 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a88b65a4-9ec7-4bc8-bd66-28414ef8f5b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125994770>]}
[0m14:47:47.739429 [info ] [Thread-5 (]: 9 of 9 OK created sql table model analytics_marts.fct_creator_monthly_performance  [[32mOK[0m in 9.04s]
[0m14:47:47.739952 [debug] [Thread-5 (]: Finished running node model.patreon_analytics.fct_creator_monthly_performance
[0m14:47:47.741643 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:47:47.742002 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:47:47.742482 [info ] [MainThread]: 
[0m14:47:47.742735 [info ] [MainThread]: Finished running 2 table models, 7 view models in 0 hours 0 minutes and 19.38 seconds (19.38s).
[0m14:47:47.743684 [debug] [MainThread]: Command end result
[0m14:47:47.779662 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/manifest.json
[0m14:47:47.783339 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/semantic_manifest.json
[0m14:47:47.787388 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/tarik/codeAlpine/sp-demo/patreon_dbt_project/target/run_results.json
[0m14:47:47.787600 [info ] [MainThread]: 
[0m14:47:47.787820 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:47:47.787976 [info ] [MainThread]: 
[0m14:47:47.788184 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=9
[0m14:47:47.791481 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 21.044615, "process_in_blocks": "0", "process_kernel_time": 0.508248, "process_mem_max_rss": "283082752", "process_out_blocks": "0", "process_user_time": 6.261385}
[0m14:47:47.791969 [debug] [MainThread]: Command `dbt run` succeeded at 14:47:47.791915 after 21.05 seconds
[0m14:47:47.792349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111392900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1250b2390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259685c0>]}
[0m14:47:47.792575 [debug] [MainThread]: Flushing usage events
[0m14:47:48.332578 [debug] [MainThread]: An error was encountered while trying to flush usage events
